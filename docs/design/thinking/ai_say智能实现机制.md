# ai_say 智能实现机制（主文档）

> **目标读者**：架构师、技术负责人、新团队成员
> **文档定位**：核心架构设计与实现原则
> **详细实现**：参见 [ai_say 实现细节参考.md](./015-ai_say实现细节参考.md)
>
> **架构思想来源**：Andrew Ng（吴恩达）的 AI 落地最佳实践 - "可观测性是 AI 系统的生命线"

---

## 🎯 设计哲学：让 AI 做它擅长的事

> **核心洞察**（Andrew Ng）：
>
> _"在 AI 时代，我们应该问的不是'如何用规则控制 AI'，而是'如何让 AI 发挥它的优势'。"_
>
> _"LLM 的强项是理解上下文、综合考虑多个因素、生成自然语言。我们应该利用这些优势，而不是用硬编码规则限制它。"_
>
> _"提示词工程（Prompt Engineering）是新时代的'编程'。好的提示词比复杂的规则引擎更强大、更灵活、更易维护。"_

### 端到端策略生成 vs. 规则映射

**❌ 传统方案（规则 + 模板）**：

```
支线B识别用户特征 → 规则引擎映射 → 选择预定义模板 → 注入主线A
```

- 需要维护 100+ 条规则
- 需要维护 100+ 个模板片段
- 灵活性受限于预定义规则
- 迭代慢（修改代码）

**✅ 我们的方案（端到端 LLM）**：

```
支线B基于脚本定义的用户画像变量 + 对话历史 → LLM端到端生成策略提示词 → 直接注入主线A
```

- 只需维护提示词（2-3 个）
- LLM 综合考虑所有因素
- 高度灵活，处理边缘情况
- 迭代快（调整提示词）

**关键优势**：

- ✅ **减少硬编码**：避免维护大量规则和模板
- ✅ **提升灵活性**：LLM 可以处理复杂和边缘情况
- ✅ **快速迭代**：通过提示词优化而非代码修改
- ✅ **更符合 AI 时代的设计哲学**：让 AI 做它擅长的事情

---

## 📌 核心理念

**ai_say 的智能实现基于四个核心认识**：

### 1. 所有的"智能"都是通过 LLM 提示词来实现的

- 用户理解、节奏控制、沟通策略、安全风险识别等，都通过提示词模板中的变量和指令实现
- 框架只需提供变量管理和流程控制，LLM 负责所有智能分析

### 2. LLM 负责识别和量化，规则负责阈值判断和流程切换

- **LLM 的职责**：识别所有语义类信息（理解度、情感、风险、重复、停滞等）并量化
- **规则的职责**：基于 LLM 量化的结果，进行阈值判断和脚本动作切换
- **规则的兜底职责**：硬性上限（最大轮次）防止无限循环
- **核心优势**：LLM 擅长语义理解，规则擅长确定性控制，各司其职

### 3. 沟通策略由 LLM 端到端生成，避免硬编码规则映射

- **支线 B 的核心职责**：基于脚本层提供的用户画像变量（如 `{用户画像}` 或按字段拆分的 `教育背景` / `心理学知识` / `学习风格` 等）、对话历史、当前情境，端到端生成沟通策略建议
- **策略提示词**：自然语言描述的策略建议（语言风格、例子类型、共鸣方式、引导方法）
- **直接注入主线 A**：无需规则映射，LLM 直接理解和应用策略建议
- **核心优势**：灵活、可扩展、易维护，符合 AI 时代的设计哲学

### 4. 可观测性是持续优化的基础

- 记录每次 LLM 的识别结果和规则的流程控制决策
- 分析数据，发现问题，优化 prompt 和阈值
- 建立"用户交互 → LLM 识别量化 → 规则流程控制 → 记录数据 → 分析优化"的闭环

---

## 第一部分：三层架构设计

### 1.1 架构定义

**ai_say 采用清晰的三层架构**，每层职责明确，符合关注点分离原则：

```
┌─────────────────────────────────────────────────────────────┐
│ 第一层：话题特定层（Topic-Specific Layer）                   │
│ • 职责：讲什么 + 话题特定的怎么讲                            │
│ • 实现：脚本内容 + 第一层变量 {变量名}                       │
│ • 例子：ABC 模型的讲解内容和顺序                             │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 第二层：特定领域通用设施层（Domain-Shared Infrastructure Layer） │
│ • 职责：在 CBT 咨询领域内跨话题共享：聊天历史、用户背景、沟通策略、时间管理 │
│ • 说明：评估维度与退出规则由脚本层以模式定义，本层负责在执行流程中统一注入与运用 │
│ • 实现：提示词模板 + 模式配置 + 第二层变量 {%变量名%}                     │
│ • 例子：{%chat%}, {%user%}, {%tone%}                        │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│ 第三层：流程编排层（Orchestration & Control Layer）          │
│ • 职责：解析推理、验证合理性、决策转向、记录轨迹              │
│ • 会谈状态与变量管理：如 current_step、assessment、strategy_prompt 等 │
│ • 调度执行流：决定何时调用支线 B（分析）/ 主线 A（执行）/ 支线 C（安全）       │
│ • 实现：可观测的决策循环（Observable Decision Loop）         │
│ • 关键：LLM 提供"建议"，规则做"决策"                         │
└─────────────────────────────────────────────────────────────┘
```

**架构优势**：

- ✅ **清晰度**：每层职责明确，边界清晰
- ✅ **可操作性**：直接映射到代码结构
- ✅ **可扩展性**：关注点分离，易于添加新功能
- ✅ **可维护性**：代码组织清晰，易于理解和修改
- ✅ **通用性**：一套框架支持所有讲解主题

**说明：系统视角的三层架构与 005 文档的对应关系**

上述三层是从 **系统实现视角** 描述 ai_say 的分层架构，用于划分「话题脚本 / CBT 领域内共享设施 / 流程编排与决策循环」。
在 `docs/thinking/docs\thinking\015 ai_say\015-ai-say-prompt-templates-with-examples.md` 中的「三层架构：职责清晰分离」，则是从 **提示词与执行流水线视角** 描述「脚本层 - 支线 B - 主线 A」。

为便于对齐，两者的映射关系如下：

- **第一层：话题特定层** ≈ **脚本层（Domain Layer）**
- **第二层：特定领域通用设施层** ≈ **CBT 领域内跨话题共享的上下文 & 策略模板 & 第二层变量**
- **第三层：流程编排层** ≈ **支线 B + 主线 A + 支线 C + 规则引擎的整体调度与决策**

### 1.2 关键原则

> **本节已按 005 文档 v2.0（2025‑01‑14）对齐：提示词与 JSON 字段以 005 为权威规范，015 只描述实现侧职责分工。**

**原则 1：LLM + 规则的正确分工（按三线架构划分职责）**

- **主线 A（执行层，LLM）**：
  - 负责**执行业务逻辑并生成本轮回复**；
  - 消费支线 B 输出的 `strategy_prompt`、`strategy_steps`、`progress_summary`、`assessment_summary` 等；
  - 在每轮输出中填充：
    - `response`：本轮给用户的自然语言回复；
    - `exit` / `exit_reason`：基于支线 B 评估与模板内联规则得出的**退出建议**（非最终决策）；
    - `risk_screening`：快速风险筛查结果（如 `urgent_risk_detected`、`risk_type`）。
  - ❌ 不再承担“深度评估”职责（理解度、接受度、抗拒等量化评估迁移到支线 B）。
- **支线 B（分析层，LLM）**：
  - 负责**深度评估 + 策略规划 + 步骤管理**；
  - 以两阶段机制运行：
    - 阶段 0（预处理）：在话题第一次开始前，同步生成 `base_steps`、初始 `strategy_steps`、`strategy_prompt`；
    - 阶段 1+：在后续轮次中，异步更新 `assessment`、`assessment_summary`、`progress_summary`、`strategy_steps`、`current_step_completion`、`step_adjustment_recommendation`、`strategy_prompt`；
  - 是**理解度/接受度/抗拒等维度的主数据来源**，为规则层与主线 A 提供结构化评估结果。
- **支线 C（监控层，LLM）**：
  - 负责**风险监控 + 干预建议**；
  - 以异步方式运行，不阻塞主线 A，同步或按需消费主线 A 的 `risk_screening`；
  - 输出 `risk_signals`、`risk_level`、`risk_assessment`、`intervention_recommendation` 等结构化安全信号，用于规则层和安全脚本路由。
- **规则层**：
  - 基于支线 B 的结构化评估结果 + 脚本定义的 `exit_criteria` / `step_adjustment_rules` + 主线 A 的 `exit`/`exit_reason` 建议，做**最终退出/继续/调整步骤**等决策；
  - 结合支线 C 输出的风险信号，决定是否中断当前话题、切换到安全话题脚本或触发外部安全流程。
- **规则兜底**：
  - 通过 `max_rounds` 等硬性上限防止无限循环；
  - 在 B 线评估不确定或 C 线风险较高时，强制启用保守策略（如提前退出、切换到安全脚本）。

**关键总结**：

- LLM 负责**语义识别与评估、策略与步骤生成、风险识别**；
- 规则负责**流程控制与安全兜底**；
- **005 文档中的字段与模板是“界面规范”，本节描述的是这些职责在实现层的落位方式。**

**原则 2：可观测的识别与控制循环**

- 每次流程控制都记录完整的上下文（LLM 识别结果 + 规则控制决策）
- 这些数据用于调试、优化 prompt、调整阈值
- 建立持续优化的闭环

**原则 3：职责清晰分离**

- 第一层：话题特定的内容和策略
- 第二层：在 CBT 咨询领域内跨话题的通用能力
- 第三层：基于 LLM 识别结果的流程控制

### 1.3 可观测的决策循环

**核心机制**：让 LLM（尤其是支线 B）输出结构化的评估与策略，而不仅仅是最终话术。

#### 支线 B LLM 输出格式（示例）

```json
{
  "assessment": {
    "understanding_level": 65,
    "has_questions": true,
    "expresses_understanding": false,
    "risk_assessment": {
      "level": "low",
      "indicators": []
    }
  },
  "assessment_summary": ["理解度：65分", "有疑问：是", "表达理解：否"],
  "progress_summary": "当前进度简要总结……",
  "strategy_steps": {
    "planned_steps": ["步骤1：...", "步骤2：..."],
    "current_step_index": 1,
    "total_steps": 2,
    "step_description": "当前步骤描述"
  },
  "strategy_prompt": "面向主线 A 的策略提示..."
}
```

#### 决策循环工作流程（按 005 的三线职责与两阶段机制重写）

```
用户输入
  ↓
【支线 B - 阶段 0（如是该 ai_say 首轮且需要 B 线支持）】
  ├─ 基于脚本 `topic_description` + 脚本定义的用户画像变量规划 `base_steps`
  ├─ 初始化 `strategy_steps`（planned_steps、current_step_index 等）
  ├─ 生成面向主线 A 的初始 `strategy_prompt`
  └─ 输出给 orchestrator（同步，主线 A 必须等待）
  ↓
【主线 A - 执行层】（每轮同步必执行）
  ├─ 读取：`topic_description`、`progress_summary`、`strategy_steps` 当前步、`strategy_prompt`、`assessment_summary`、最近对话窗口
  ├─ 生成本轮 `response`
  ├─ 根据模板内联规则 + `assessment_summary` 给出 `exit` / `exit_reason` 建议
  ├─ 完成快速 `risk_screening`（是否存在紧急风险、`risk_type`）
  └─ 输出结构化 JSON（对外暴露：`response` + `exit` + `exit_reason` + `risk_screening`）
  ↓
【发送给用户】（正常情况下不等待 B / C 的异步结果）
  ↓
【支线 B - 阶段 1+（异步，每 2–3 轮执行一次）】
  ├─ 输入：`base_steps`、上一轮 `strategy_steps`、分层会谈上下文、上一轮主线 A 输出等
  ├─ 更新 `assessment` / `assessment_summary`
  ├─ 更新 `progress_summary`
  ├─ 更新 `strategy_steps`（含 `current_step_index`、`planned_steps`）
  ├─ 生成/更新 `current_step_completion`、`step_adjustment_recommendation`
  └─ 输出新的 `strategy_prompt` 供后续轮次主线 A 使用
  ↓
【支线 C - 监控层（异步，按需触发）】
  ├─ 输入：会谈历史 / 本轮主线 A 的 `risk_screening` / 用户安全相关历史等
  ├─ 输出：`risk_signals`、`risk_level`、`risk_assessment`、`intervention_recommendation`
  └─ 供规则层与安全脚本路由使用
  ↓
【规则层】
  ├─ 基于支线 B 的 `assessment` / `assessment_summary`、`progress_summary`
  ├─ 结合脚本 `exit_criteria` / `step_adjustment_rules`
  ├─ 参考主线 A 的 `exit` / `exit_reason` 建议与支线 C 的风险信号
  └─ 做出最终决策：`continue` / `exit` / `abort` / `adjust_steps` / `route_to_safety_topic` 等
  ↓
【记录轨迹】用于优化与调试（保留每一轮 LLM 输出与规则决策）
```

**核心价值**：

- ✅ 主线 A 专注当前回合的执行与退出/风险**建议**，不承担深度评估主职责；
- ✅ 支线 B 拥有完整的两阶段机制，负责理解度/接受度/抗拒等维度的主数据与步骤规划；
- ✅ 支线 C 仅在主线A初识风险后启动，专注风险详细评估，给出对策，修订本轮回复；
- ✅ 规则层统一消费 B/C 输出与脚本规则，做最终退出/中止/步骤调整决策；
- ✅ 响应路径中仅主线 A 为同步必经点，B/C 通常异步执行，保证体验；
- ✅ 决策链路完全可观测，便于按照 005 文档中的字段与模板做 A/B 测试和阈值调优。

---

## 第二部分：智能能力实现

### 2.1 智能能力清单

| 智能能力            | 实现机制                                      | 关键输入                                                       |
| ------------------- | --------------------------------------------- | ---------------------------------------------------------------- |
| **用户理解适配**    | 主线 A 根据用户基础信息自动调整讲解深度       | 来自脚本变量的教育背景、心理学知识、学习风格、用户经历           |
| **语言风格适配**    | 主线 A 根据用户语言偏好自动调整表达方式       | 来自脚本变量的词汇水平、语言风格、常用表达                       |
| **节奏控制**        | 主线 A 根据剩余时间和讲解进度自动调整节奏     | 讲解进度、剩余时间                                             |
| **沟通策略生成** ⭐ | **支线 B 端到端生成沟通策略建议**（自然语言） | 脚本定义的用户画像变量、对话历史、当前情境、治疗阶段             |
| **疑问识别**        | 主线 A 分析用户消息，识别显式和隐式疑问       | 最近聊天记录                             |
| **理解度评估**      | 主线 A 根据用户回复评估理解度                 | 最近聊天记录、讲解进度                   |
| **跑题判断**        | 主线 A 计算用户问题与主题的关联度             | 主题提示词、最近聊天记录                 |
| **风险识别**        | 主线 A 识别自伤、自杀、情绪崩溃等风险         | 最近聊天记录、用户情感特点               |
| **进度跟踪**        | 支线 B 分析对话历史，识别已讲解和剩余内容     | 完整对话历史、主题提示词                 |
| **策略步骤规划**    | 支线 B 规划讲解步骤，动态调整执行顺序         | 主题提示词、用户理解情况                 |
| **质量监控**        | 支线 B 检测重复、停滞，优化策略               | 完整对话历史、主线 A 输出                |

**核心设计理念**：

- ✅ **主线 A**：执行当前回合的对话（理解度评估、风险识别、回复生成）
- ✅ **支线 B**：深度分析 + **端到端策略生成**（无需规则映射）
- ✅ **规则层**：基于 LLM 量化结果做阈值判断和流程切换

> 📘 **详细实现**：
>
> - 提示词模板：参见 [实现细节参考文档 §1](./015-ai_say智能实现细节参考.md#第一部分完整提示词模板)
> - 三线协同代码：参见 [实现细节参考文档 §2](./015-ai_say智能实现细节参考.md#第二部分三线协同完整代码实现)
> - 策略步骤执行：参见 [实现细节参考文档 §7.6](./015-ai_say智能实现细节参考.md#76-策略步骤执行详细实现)

### 2.2 提示词模板切换机制

#### 核心思想

**问题**：单一提示词包含所有任务会导致：

- LLM 负担过重，可能无法很好执行所有要求
- 提示词过长，增加成本和延迟
- 不同状态下的需求不同

**解决方案**：根据状态切换不同的提示词模板

#### 提示词模板类型

| 模板类型         | 使用场景   | 核心任务                       | 特点               |
| ---------------- | ---------- | ------------------------------ | ------------------ |
| **标准模板**     | 正常对话   | 理解度评估、回复生成、风险识别 | 完整功能           |
| **简洁模板**     | 时间不足   | 快速回复、基础评估             | 精简指令，更快响应 |
| **跑题拉回模板** | 用户跑题   | 识别跑题原因、温和拉回         | 专注话题相关性     |
| **阻抗探索模板** | 检测到阻抗 | 探索阻抗原因、调整策略         | 专注情感和动机     |
| **危机评估模板** | 高风险信号 | 详细风险评估、安全计划         | 专注安全评估       |

#### 模板切换规则

```typescript
function selectPromptTemplate(
  context: AiSayContext,
  llmPreviousOutput?: LLMReasoning
): PromptTemplate {
  // 规则 1: 时间不足 → 简洁模板
  if (context.remainingTime < 5) {
    return CONCISE_TEMPLATE;
  }

  // 规则 2: 检测到跑题 → 跑题拉回模板
  if (llmPreviousOutput?.topic_alignment < 0.5) {
    return OFF_TOPIC_TEMPLATE;
  }

  // 规则 3: 检测到阻抗 → 阻抗探索模板
  if (llmPreviousOutput?.resistance_score >= 7) {
    return RESISTANCE_TEMPLATE;
  }

  // 规则 4: 高风险信号 → 危机评估模板
  if (llmPreviousOutput?.risk_assessment.level === "high") {
    return CRISIS_TEMPLATE;
  }

  // 默认：标准模板
  return STANDARD_TEMPLATE;
}
```

### 2.3 变量系统设计

#### 变量分类

| 变量类型       | 更新频率   | 更新方式                          | 示例                             |
| -------------- | ---------- | --------------------------------- | -------------------------------- |
| **静态变量**   | 初始化一次 | 从脚本变量/会谈初始化载入（如`用户画像`） | 教育背景、职业、兴趣             |
| **半静态变量** | 偶尔更新   | 由支线 B 基于对话历史和用户变量分析更新  | 学习风格、认知特点、情感特点     |
| **动态变量**   | 每轮更新   | 从当前对话计算                      | 讲解进度、剩余时间、最近聊天记录 |
| **策略提示词** | 异步生成   | 支线 B 端到端生成 | 自然语言的沟通策略建议（见下文） |

#### 核心变量列表

**用户模型变量**（用于支线 B 生成策略）：

- 来自脚本 YAML 中声明的画像相关变量：教育背景、心理学知识、学习风格、认知特点、情感特点、用户经历（可以集中在一个多行变量如 `用户画像` 中，也可以按字段单独声明）

**语言偏好变量**（用于支线 B 生成策略）：

- 词汇水平、语言风格、常用表达

**上下文变量**（用于主线 A 和支线 B）：

- 讲解进度、剩余时间、最近聊天记录

**策略提示词**（支线 B 端到端生成，直接注入主线 A）：

- **不再是预定义的变量**，而是支线 B 基于脚本提供的用户画像变量、对话历史、当前情境，端到端生成的自然语言策略建议
- **示例格式**（自然语言）：

  ```
  【沟通策略建议】

  1. **语言风格**：半正式、中等复杂度、委婉
     - 理由：用户本科学历，但当前情绪低落，需要温和表达

  2. **例子类型**：具体的个人经历例子
     - 理由：用户学习偏好是具体案例，抽象概念理解较慢

  3. **共鸣策略**：高强度情绪验证 + 普遍化
     - 理由：用户表达强烈的孤独感，需要先验证情绪再普遍化

  4. **引导方式**：反思引导为主，避免直接教育
     - 理由：用户有一定心理学知识，苏格拉底式提问更有效
  ```

- **关键优势**：
  - ✅ 无需维护规则映射（LLM 综合考虑所有因素）
  - ✅ 灵活处理边缘情况（LLM 可以处理未预见的情况）
  - ✅ 快速迭代（调整支线 B 提示词即可）

#### 用户画像属性分类

根据属性的稳定性和更新频率，我们将用户画像属性分为两类：

**静态属性 (Static Properties)**：
这些是相对稳定的个人信息，在一次咨询会话中基本不会改变：

- `educationLevel` - 学历水平
- `age` - 年龄  
- `occupation` - 职业
- `gender` - 性别
- `learningStyle` - 学习风格

**动态属性 (Dynamic Properties)**：
这些属性会在对话过程中发生变化：

- `currentEmotion` - 当前情绪状态
- `psychologyKnowledge` - 心理学知识水平（可能会随着对话进展而更新理解）
- `engagementLevel` - 参与度
- `cognitiveAbility` - 当前认知能力
- `stressLevel` - 压力水平

这种分层设计的好处：

1. **性能优化** - 静态属性只需初始化一次，减少重复计算
2. **精准策略** - 动态属性可以实时影响对话策略调整
3. **配置灵活** - 脚本层可以定义哪些属性是静态或动态的
4. **领域适配** - 不同咨询场景可以有不同的属性分类方式

在实现层面，这些属性完全通过变量系统来管理，不需要专门的UserProfile对象。静态属性在会话初始化时从脚本中加载，动态属性在对话过程中由支线B分析更新。

> 📘 **完整的策略生成提示词模板**：参见 [本文档 §3.2.1](#321-策略生成提示词模板完整版) ⭐

### 2.4 提示词设计要点

**提示词模板结构**（简化版）：

```
你是 CBT 咨询师，正在向来访者进行心理教育。

【讲解主题】{%theme提示词%}
【最近对话历史】{%最近10回合聊天记录%}
【用户基础信息】{%教育背景%}、{%心理学知识%}、{%学习风格%}
# 上述画像字段均来自脚本 YAML 中声明的变量（例如 `var: 教育背景`，或一个多行 `var: 用户画像`，由变量系统在会谈开始时载入并映射到这些占位符）
【当前上下文】{%讲解进度%}、{%剩余时间%}

【沟通策略建议】⭐ 支线 B 端到端生成，直接注入
{%strategy_prompt%}

【你的任务】
1. 识别并量化用户理解度 (0-100)
2. 识别用户情感状态（confident/uncertain/frustrated/engaged）
3. 识别并量化安全风险等级（low/medium/high）及具体指标
4. 识别并量化阻抗程度 (0-10)
5. 判断用户是否表达了理解意图（语义判断，非关键词匹配）
6. 识别用户疑问
7. **基于上述沟通策略建议**，生成回复

【输出格式】
{
  "reasoning": {
    "understanding_level": 0-100,
    "user_sentiment": "confident|uncertain|frustrated|engaged",
    "risk_assessment": {
      "level": "low|medium|high",
      "indicators": ["具体风险指标"]
    },
    "resistance_score": 0-10,
    "expresses_understanding": true/false,
    "identified_questions": ["问题1", "问题2"]
  },
  "response": { "咨询师": "..." }
}
```

**{%strategy_prompt%} 示例**（支线 B 生成）：

```
【沟通策略建议】

1. **语言风格**：半正式、中等复杂度、委婉
   - 理由：用户本科学历，但当前情绪低落，需要温和表达

2. **例子类型**：具体的个人经历例子
   - 理由：用户学习偏好是具体案例，抽象概念理解较慢

3. **共鸣策略**：高强度情绪验证 + 普遍化
   - 理由：用户表达强烈的孤独感，需要先验证情绪再普遍化

4. **引导方式**：反思引导为主
   - 理由：用户有一定心理学知识，反思引导比直接教育更有效
```

**关键洞察**：

- ✅ LLM 负责所有语义识别和量化（包括安全风险）
- ✅ **沟通策略由支线 B 端到端生成**，无需规则映射
- ✅ 主线 A 直接理解和应用自然语言的策略建议
- ✅ 规则层基于量化结果做阈值判断和流程切换
- ✅ 框架只需负责变量的收集、更新和流程控制

> 📘 **详细提示词模板**：
>
> - 主线 A 提示词：参见 [实现细节参考文档 §1](./015-ai_say智能实现细节参考.md#第一部分完整提示词模板)
> - **支线 B 策略生成提示词**：参见 [本文档 §3.2.1](#321-策略生成提示词模板完整版) ⭐

### 2.5 ai_say subtype 自动推断与脚本补齐

> 设计思路（Andrew Ng 风格）：
>
> - **让 AI 做擅长的事**：脚本作者不必为每个 ai_say 手工分类，交给 LLM 来做语义理解与分类；
> - **在人类擅长的层面留出控制权**：显式 subtype 仍然保留，给高级用户/调试场景使用；
> - **只在低频路径调用 LLM**：在脚本加载/验证阶段一次性推断，而不是每轮对话都推断，控制成本和延迟。

#### 2.5.1 设计目标

- 让 CBT 工程师/咨询师写脚本时**尽量不需要关心 subtype 细节**；
- 通过描述（`topic` / `concept` / `description`）自动识别 ai_say 的场景类型；
- 为支线 B 提供稳定的 `ai_say_subtype` / `ai_say_subtype_hint` 变量，用于选择合适的评估维度和解释任务重点。

#### 2.5.2 工作流程（脚本加载与验证）

1. **脚本加载**：
   - 将 YAML/JSON 中的 `CounselingScript` 加载为领域对象（聚合根）。
2. **语义分析预处理（应用层 / 领域服务）**：
   - 对所有 `ai_say` 动作进行扫描；
   - 对于**没有显式 subtype** 的 ai_say，调用一个小型 LLM 服务：
     - 输入：`topic`、`concept`、`description`、所在阶段/步骤等上下文；
     - 输出：
       - 建议的 `subtype`（如 `introduce_concept` / `persuade` / `train_intro` / ...）；
       - 自然语言解释（`subtype_hint`，说明这是哪类任务、关注什么维度）；
       - 置信度（0-1）。
3. **补齐策略**：
   - 如果该 ai_say **已有显式 subtype** → 直接尊重脚本作者配置，不做覆盖；
   - 如果没有显式 subtype，且 LLM 置信度 ≥ 阈值（如 0.7）：
     - 在内存中的脚本对象上填充 `subtype`；
     - 同时生成对应的 `ai_say_subtype_hint`，作为支线 B 提示词变量；
   - 如果置信度不足 → 保持 subtype 为空，标记为“需人工确认”或回退到保守的默认策略。
4. **领域验证（CounselingScript.validate）**：
   - 验证所有**需要支线 B 支持的 ai_say** 在完成预处理后都具备有效的 subtype；
   - 若仍有缺失，可：
     - 在开发环境/脚本设计工具中报告为错误或警告；
     - 在生产环境中回退到默认行为（例如使用最基础的评估维度，只做理解度+疑问+情绪的评估）。

> 实现层面上，LLM 调用应通过应用服务 / 领域服务接口完成，**不要在聚合根内部直接依赖基础设施**，以保持领域模型的纯净性。

#### 2.5.3 subtype → 支线 B 提示词的映射

预处理完成后，框架会为支线 B 提供两个变量：

- `ai_say_subtype`：机器可读的场景代码（`introduce_concept` / `persuade` / `train_intro` / ...）；
- `ai_say_subtype_hint`：给 LLM 使用的自然语言说明，解释本轮 ai_say 的**任务类型和评估重点**。

示例映射（与 005 文档中的支线 B 模板保持一致）：

- `introduce_concept` →
  - `ai_say_subtype_hint`：
    - “当前是**知识讲解**场景，重点评估用户对概念的理解度、是否有疑问、情绪反应，以及是否表达了‘我懂了’。”
- `persuade` →
  - `ai_say_subtype_hint`：
    - “当前是**说服/邀请尝试**场景，重点评估用户的接受度、抗拒程度、是否表达愿意尝试，以及是否仍有重要顾虑。”
- `train_intro` →
  - `ai_say_subtype_hint`：
    - “当前是**技能训练前说明**场景，重点评估用户对训练目的的理解、练习准备度，以及是否需要调整训练安排。”

这些映射不要求脚本作者维护，

- 在脚本层只需要（可选地）写 `subtype`；
- 在提示词层通过 `{%ai_say_subtype%}` 和 `{%ai_say_subtype_hint%}` 变量使用；
- 在实现层统一维护 subtype → hint 的映射表，便于集中调整。

> 总结：通过一次性的 LLM 预处理，我们用极小的成本，换来**脚本的简洁性**和**系统对场景类型的清晰感知**，同时保留了高级用户通过显式 subtype 精调的能力。这样既符合 Andrew Ng 所说的“在低频路径上使用更强大的 AI”，也让 CBT 工程师的日常工作保持简单自然。

#### 2.5.4 subtype → 主线 A / 支线 B / 支线 C 三份提示词模板组

在 CBT 这个相对收敛的领域内，ai_say 的 subtype 数量是有限的（如 `introduce_concept` / `persuade` / `train_intro` / ...）。为避免在当前阶段过早引入复杂的 schema + 模板拼装系统，本设计在提示词层采用一个**更直接的实现策略**：

- 每个 subtype 拥有自己的一组提示词模板：
  - 主线 A：一份专门面向该 subtype 的执行层模板；
  - 支线 B：一份专门面向该 subtype 的分析层模板；
  - 支线 C：一份专门面向该 subtype 的风控层模板（部分 subtype 可以共用同一版本）。
- 不同 subtype 的三份模板在结构上可以**完全不同**：
  - 可以有不同的【评估维度】说明；
  - 可以有不同的【你的任务】分解；
  - 可以有不同的 `assessment` / `exit_recommendation` 字段结构。

运行时流程（与前文 subtype 自动补齐配合）：

1. 脚本加载与 subtype 补齐完成后，每个 ai_say 都有一个确定的 `subtype`。
2. 引擎根据 `subtype` 查找对应的「提示词模板组」：
   - `mainline_a_template_id` → 主线 A 所用模板；
   - `branch_b_template_id` → 支线 B 所用模板；
   - `branch_c_template_id` → 支线 C 所用模板。
3. 在每条线内部，再按 §2.2 的规则选择具体变体（标准 / 简洁 / 危机评估等），并完成两层变量替换：
   - 第一层：脚本变量 `{变量名}`；
   - 第二层：系统变量 `{%变量名%}`（含 `ai_say_subtype` / `ai_say_subtype_hint` 等）。

> 这种做法有意在早期阶段选择「**每个 subtype 三份模板**」的简单实现：
>
> - ✅ CBT 工程师可以针对不同 subtype 自由设计最合适的提示词结构；
> - ✅ 不强迫所有场景共享同一个巨大的评估 schema；
> - ✅ 保留未来演进空间：当 subtype 种类真正变多、复用需求变强时，可以再把共用的评估维度与退出条件抽象为集中配置（见 005 文档中 subtype profiles 的设想），由引擎生成局部模板片段。

---

## 第三部分：三线协同优化架构

### 3.1 架构设计动机

**单 LLM 的局限**：

- 需要同时完成多个任务（生成回复、评估理解度、识别风险等）
- 沟通策略的优化需要在下一轮对话才能体现
- 高风险情况下缺乏审核机制

**三线协同的优势**：

- ✅ 主线 A 专注于快速生成回复 + 退出/快速风险筛查建议（不承担深度评估）
- ✅ 支线 B 专注于深度分析和策略优化（异步）
- ✅ 支线 C 专注于风险控制与干预建议（条件触发、同步）
- ✅ 平衡速度、安全性和智能度

### 3.2 三线分工架构

#### 主线 A：核心对话引擎（同步，必执行）

**职责**：生成回复 + 退出/快速风险筛查建议（按 005 文档的 MainLineOutput）
**响应时间**：2-3 秒
**执行频率**：每轮必执行

```typescript
interface MainLineOutput {
  response: {
    咨询师: string;
  };
  exit: boolean;
  exit_reason: string;
  risk_screening: {
    urgent_risk_detected: boolean;
    risk_type:
      | "suicide"
      | "self_harm"
      | "crisis_emotion"
      | "severe_distortion"
      | "alliance_rupture"
      | null;
  };
}
```

**设计原则**：

- ✅ **一次调用完成核心任务**：回复生成 + 关键状态识别
- ✅ **响应速度优先**：2-3 秒内完成
- ✅ **内置风险识别**：识别潜在风险信号，但不负责审核和修订内容

#### 支线 B：质量监控 + 策略生成引擎（异步，每轮执行）

**职责**：深度分析 + 质量监控 + **沟通策略生成**
**响应时间**：不限制（异步后台）
**执行频率**：每轮异步执行

```typescript
interface SupportLineBOutput {
  // 质量监控（原有功能）
  quality_monitoring: {
    repetition_detection: {
      semantic_repetition: boolean;
      strategy_repetition: boolean;
      severity: "low" | "medium" | "high";
    };
    stagnation_detection: {
      understanding_plateau: boolean;
      engagement_decline: boolean;
      duration: number; // 轮次
    };
  };

  // 沟通策略生成（新增核心功能）⭐
  strategy_prompt: string; // 自然语言的策略建议，直接注入主线 A

  // 策略生成的推理过程（可观测性）
  strategy_reasoning: {
    user_state_analysis: string; // 用户当前状态分析
    key_considerations: string[]; // 关键考虑因素
    strategy_rationale: string; // 为什么选择这些策略
  };
}
```

**策略提示词示例**（支线 B 端到端生成）：

```
【沟通策略建议】

1. **语言风格**：
- 正式程度：半正式
- 复杂度：中等
- 直接性：委婉
- 理由：用户本科学历，但当前情绪低落，需要温和表达

2. **例子类型**：
- 抽象程度：具体
- 来源：个人经历
- 情感倾向：正面
- 理由：用户学习偏好是具体案例，需要正面例子提升信心

3. **共鸣策略**：
- 主要策略：验证情绪 + 普遍化
- 强度：高
- 理由：用户表达强烈的孤独感，需要先验证情绪再普遍化

4. **引导方式**：
- 风格：反思引导
- 指导性：中
- 理由：用户有一定心理学知识，反思引导比直接教育更有效

5. **具体建议**：
- 开场建议：先验证用户的情绪体验
- 关键提问：引导用户反思情绪背后的想法
- 注意事项：避免过早进入认知层面，先稳定情绪
```

**设计原则**：

- ✅ **异步执行**：不阻塞当前回复
- ✅ **深度分析**：可以花更多时间和 token
- ✅ **端到端策略生成**：基于脚本层提供的用户画像变量、对话历史、当前情境，LLM 综合推理生成策略建议
- ✅ **无需规则映射**：直接生成自然语言策略提示词，主线 A 可以直接理解和应用
- ✅ **可观测性**：记录策略生成的推理过程，便于调试和优化

---

#### 3.2.1 策略生成提示词模板（完整版）

> **设计思想来源**：Andrew Ng 的端到端 LLM 策略生成理念

**核心目标**：让支线 B 基于脚本定义的用户画像变量、对话历史、当前情境，端到端生成个性化的沟通策略建议，无需规则映射。

##### 完整提示词模板

```
你是一位 CBT 咨询策略专家，负责为主线咨询师生成个性化的沟通策略建议。

【用户画像】
- 教育程度：{%education_level%}（graduate/undergraduate/high_school/below）
- 年龄：{%age%}
- 认知风格：{%cognitive_style%}（analytical/practical/mixed）
- 学习偏好：{%learning_preference%}（experiential/observational/reading）
- 心理学知识：{%psychology_knowledge%}（0-100）

【当前情绪状态】
- 情绪类型：{%current_emotion%}（anxious/depressed/hopeless/defensive/calm）
- 情绪强度：{%emotion_intensity%}（0-100）
- 认知能力：{%cognitive_ability%}（0-100，当前可用的认知资源）

【对话历史分析】
- 治疗阶段：{%therapeutic_phase%}（early/middle/late）
- 当前话题：{%current_topic%}
- 话题复杂度：{%topic_complexity%}（simple/moderate/complex）
- 最近20轮对话：
{%recent_conversation%}

【用户最近表现】
- 理解度趋势：{%understanding_trend%}（improving/stable/declining）
- 参与度：{%engagement_level%}（0-10）
- 困惑信号数：{%confusion_signals%}（0-N）
- 使用专业术语：{%uses_technical_terms%}（true/false）
- 表达的主要需求：{%expressed_needs%}

【任务】
基于以上信息，为主线咨询师生成四个维度的沟通策略建议。

【输出格式】
{
  "reasoning": {
    "user_state_analysis": "用户当前状态的综合分析（情绪、认知、参与度、理解度）",
    "key_considerations": [
      "关键考虑因素1（如：情绪强度高，需要先稳定情绪）",
      "关键考虑因素2（如：教育程度高，可以使用专业术语）",
      "关键考虑因素3（如：理解度下降，需要简化语言）"
    ],
    "strategy_rationale": "为什么选择这些策略的整体理由"
  },

  "strategy_prompt": "
【沟通策略建议】

1. **语言风格**：
   - 正式程度：[formal/semi-formal/casual]
   - 复杂度：[simple/moderate/complex]
   - 直接性：[direct/indirect/balanced]
   - 理由：基于{%education_level%}、{%age%}、{%current_emotion%}的综合判断
   - 具体建议：[如：使用'您'而非'你'，避免专业术语，用短句表达]

2. **例子类型**：
   - 抽象程度：[concrete/semi-abstract/abstract]
   - 来源：[personal/universal/professional/analogical]
   - 情感倾向：[positive/negative/neutral/mixed]
   - 理由：基于{%cognitive_style%}、{%learning_preference%}、{%current_emotion%}的判断
   - 具体建议：[如：使用用户刚才提到的具体经历，避免抽象概念]

3. **共鸣策略**：
   - 主要策略：[validate_emotion/normalize_experience/collaborative_stance/connect_to_cognition]
   - 强度：[high/moderate/low]
   - 表达方式：[direct_statement/reflective_listening/universalizing]
   - 理由：基于{%emotion_intensity%}、{%therapeutic_phase%}的判断
   - 具体建议：[如：先反映用户的情绪'我听到您现在感到...'，再普遍化'很多人在这种情况下...']

4. **引导方式**：
   - 风格：[socratic/didactic/reflective/collaborative]
   - 指导性：[high/moderate/low]
   - 提问类型：[open_ended/closed_ended/clarifying]
   - 理由：基于{%therapeutic_phase%}、{%psychology_knowledge%}、{%topic_complexity%}的判断
   - 具体建议：[如：使用苏格拉底式提问'您觉得这个想法有什么证据？'而非直接告知]

5. **整体协调性检查**：
   - 四个维度是否协调一致？[如：高情绪强度时，语言应简单+共鸣应高+引导应温和]
   - 是否符合当前治疗阶段？[如：早期重教育，中期重探索，晚期重巩固]
   - 是否考虑了用户的认知资源？[如：认知能力低时，避免复杂引导]

6. **关键注意事项**：
   - [如：用户当前情绪强度85/100，避免过早进入认知层面]
   - [如：用户连续3轮表示困惑，需要大幅简化语言]
   - [如：用户使用了专业术语，可以适度提升复杂度]
  "
}
```

##### 关键设计要点（Andrew Ng 的洞察）

**1. 数据源清晰映射**

每个维度的判断都明确依赖哪些变量：

- **语言风格** ← `education_level`, `age`, `current_emotion`
- **例子类型** ← `cognitive_style`, `learning_preference`, `current_emotion`
- **共鸣策略** ← `emotion_intensity`, `therapeutic_phase`
- **引导方式** ← `therapeutic_phase`, `psychology_knowledge`, `topic_complexity`

**2. 可观测性优先**

- `reasoning` 部分记录完整的推理过程
- 每个维度都说明"理由"
- 便于调试和优化

**3. 整体协调性检查**

- LLM 自己检查四个维度是否协调
- 避免矛盾（如：高情绪强度 + 复杂语言）

**4. 具体可执行**

- 不只是给出维度选项（如"casual"）
- 还给出具体建议（如"使用'你'而非'您'"）
- 主线 A 可以直接理解和应用

**5. 动态适应**

- 基于 `recent_conversation` 和 `understanding_trend` 动态调整
- 不是静态的规则映射

**核心优势**：

- ✅ **端到端生成**：LLM 综合考虑所有因素，无需规则映射
- ✅ **可解释性强**：每个决策都有明确的理由
- ✅ **灵活适应**：可以处理 100+ 维度的组合
- ✅ **快速迭代**：调整提示词即可优化策略

> 📘 **沟通策略维度详细设计**：参见 [沟通策略维度设计与实现](./016-沟通策略维度设计与实现.md)

---

#### 支线 C：安全审核与修订引擎（条件触发，在主线 A 检测到高风险时启动）

**职责**：审核并修订主线 A 生成的回复内容
**响应时间**：2-3 秒（串行）
**触发频率**：仅在主线 A 检测到高风险时触发（约 5-10% 的对话）

```typescript
interface SafetyReview {
  needs_correction: boolean;
  corrected_response?: string;
  correction_reason?: string;
  escalation_required: boolean;
}
```

**触发条件**：

- 主线 A 识别 `risk_level === 'high'`
- 或包含敏感关键词
- 或用户表达强烈负面情绪

**工作机制**：

支线C不是异步进行监控，而是基于主线A的初步风险识别结果来同步启用：

1. **主线A初识别**：主线A在生成回复的过程中，同时进行紧急风险的初步识别
2. **条件触发**：一旦主线A识别到高风险信号，立即同步启用支线C
3. **内容审核与修订**：支线C对主线A生成的内容进行确认，针对风险进行更细粒度的识别
4. **即时判断与修订**：支线C及时判断是否需要切换话题或调整主线A的节奏，若存在紧急风险，则直接修订主线A的回复

**设计原则**：

- ✅ **条件触发**：仅在检测到高风险信号时启动，不是每轮都执行
- ✅ **审核与修订**：对即将发送给用户的回复内容进行审核，必要时进行修订以确保安全性
- ✅ **与主线 A 协作**：基于主线 A 的风险筛查结果工作，不独立进行风险评估
- ✅ **高效执行**：在 2-3 秒内完成审核和修订工作

### 3.3 执行流程对比

#### 场景 1：正常对话（90-95% 的情况）

```
T0: 用户输入
T1: 主线 A 执行（2-3秒）
    ├─ 生成回复
    ├─ 评估理解度、情感、风险
    └─ risk_level = 'low'
T2: 直接发送回复 ✓（总延迟：2-3秒）
T3: 支线 B 异步分析（后台，不阻塞）
    └─ 为下轮对话优化策略
```

#### 场景 2：高风险对话（5-10% 的情况）

```
T0: 用户输入
T1: 主线 A 执行（2-3秒）
    ├─ 生成回复
    ├─ 评估状态
    └─ risk_level = 'high'
T2: 触发支线 C（2-3秒，串行）
    ├─ 审核主线 A 的回复
    ├─ 必要时修正内容
    └─ 确保安全
T3: 发送修正后回复 ✓（总延迟：4-6秒）
T4: 支线 B 异步分析（后台）
```

### 3.4 核心设计要点

**为什么主线 A 内置风险识别？**

- ✅ 一次 LLM 调用完成多项识别（回复生成 + 理解度 + 风险 + 参与度等）
- ✅ 成本最低，不需要额外的风险检测调用
- ✅ LLM 擅长语义理解，能识别文字中的风险信号
- ✅ 发送前就知道风险等级，规则层可以基于阈值拦截
- ✅ 逻辑最清晰，生成和检测在同一个上下文中

**为什么支线 C 只在高风险时触发？**

- ✅ 大多数对话无延迟（90-95% 的对话只需 2-3 秒）
- ✅ 高风险才审核（只有 5-10% 的对话需要支线 C）
- ✅ 平衡安全和体验（不过度设计）
- ✅ 规则层基于 LLM 的风险等级量化做判断

**为什么支线 C 不再是风险监控？**

- ✅ **职责转变**：支线 C 的职责已从风险监控转变为风险识别后的严谨复核
- ✅ **条件触发**：仅当主线 A 检测到高风险信号时才启动，而非持续监控
- ✅ **审核焦点**：专注于对已识别风险的回复内容进行细致审核和必要修订
- ✅ **安全保障**：确保在紧急风险情况下能及时干预并修订不当内容

**为什么支线 B 始终异步？**

- ✅ 不影响当前回复效率（当前回复已经发送）
- ✅ 可以花更多时间（深度分析用户模型和沟通策略）
- ✅ 逐轮优化（每轮对话都在改进）
- ✅ 咨询过程的元干预（监控关系动态，设置界限，透明化过程，策略调整，节奏控制）

> 📘 **完整代码实现**：参见 [实现细节参考文档](./015-ai_say实现细节参考.md) 第二部分

---

## 第四部分：退出与中止机制设计

### 4.1 退出 vs 中止的区别

**核心概念**：

- **退出**（Exit）：用户已理解，自然过渡到下一话题（✅ 成功完成）
- **中止**（Abort）：用户未理解，但需要主动停止当前话题（⚠️ 提前终止）

**AI 智能水平的体现**：

- ❌ **低智能**：机械执行，不会中止，强推内容
- ✅ **高智能**：识别情境，灵活应对，保护用户

### 4.2 退出条件识别

#### 退出条件类型

| 退出条件         | 识别方式     | 判断位置 | JSON 输出字段                      |
| ---------------- | ------------ | -------- | ---------------------------------- |
| **理解度达标**   | LLM 评估     | 主线 A   | `understanding_level: 85`          |
| **无疑问**       | LLM 识别     | 主线 A   | `identified_questions: []`         |
| **用户明确表示** | LLM 语义判断 | 主线 A   | `expresses_understanding: true`    |
| **最大轮次**     | 规则判断     | 规则层   | `currentRound >= maxRounds`        |
| **风险识别**     | LLM 识别     | 主线 A   | `risk_assessment: {level: "high"}` |

#### 设计原则：用 LLM 语义判断替代关键词匹配

**为什么不用关键词匹配？**

- ❌ **脆弱性**：无法捕捉语义变化（"原来是这样"、"这个我知道了"）
- ❌ **假阳性**：疑问句也可能包含关键词（"是这样对吧？"）
- ❌ **维护成本**：需要不断添加新的关键词变体
- ❌ **无法量化**：难以给出 0-100 的理解度评分

**为什么用 LLM 语义判断和量化？**

- ✅ **语义理解**：能理解隐含的理解表达
- ✅ **上下文感知**：能区分疑问和确认
- ✅ **灵活性**：自动适应各种表达方式
- ✅ **准确性**：结合上下文和语气，减少误判
- ✅ **量化能力**：能给出 0-100 的理解度评分，便于规则层做阈值判断

**这是典型的"用 LLM 语义理解替代规则穷举"的场景**，符合现代 NLP 最佳实践。

#### 规则层实现（核心逻辑）

**核心思想**：规则层综合考虑支线B的评估结果和主线A的退出标记来做出最终决策

```typescript
function evaluateExitRules(
  branchBAssessment: BranchBAssessment, // 支线B的评估结果
  mainLineOutput: MainLineOutput,        // 主线A的输出
  context: AiSayContext
): ExitDecision {
  // 兜底保护：最大轮次限制防止无限循环
  if (context.currentRound >= context.maxRounds) {
    return { shouldExit: true, exitReason: "max_rounds_reached" };
  }

  // 主要依据：主线A标记退出时才真正退出
  if (mainLineOutput.exit === true) {
    return { 
      shouldExit: true, 
      exitReason: mainLineOutput.exit_reason || "mainline_a_exit_signal" 
    };
  }

  // 支线B建议准备退出时，向主线A添加退出提示词
  if (branchBAssessment.should_exit) {
    return { 
      shouldPrepareExit: true, 
      action: "add_exit_prompt_to_mainline",
      exitReason: branchBAssessment.exit_reason || "branch_b_recommended_exit" 
    };
  }

  // 默认继续对话
  return { shouldExit: false, action: "continue" };
}
```

**关键点**：

- ✅ 支线B负责评估并建议是否准备退出
- ✅ 主线A负责实际执行退出（标记exit=true时才算真正退出）
- ✅ 规则层综合两者信息做出最终决策
- ✅ 规则层负责流程切换（退出/继续）和兜底保护

---

### 4.3 支线 B：对话质量监控（LLM 异常检测）

#### 4.3.1 支线 B 评估与规则层决策的协作机制

在 ai_say 的智能退出机制中，支线 B、规则层和主线 A 之间形成了一个紧密协作的决策循环。这个机制确保了既能及时识别用户理解情况，又能做出恰当的退出决策。

##### 协作流程概述

整个协作机制遵循以下四个关键步骤：

1. **支线 B 进行深度评估并生成结构化评估结果**
   - 支线 B 基于对话历史和用户表现，对多个维度进行评估，包括理解度(understanding_level)、接受度、抗拒程度等
   - 生成结构化的评估结果，包括量化评分和自然语言总结

2. **规则层基于评估结果进行决策**
   - 规则层接收支线 B 的结构化评估结果
   - 结合预设的退出标准和当前对话上下文，判断是否应该准备退出
   - 如果决定准备退出，则触发向主线 A 添加退出提示词的操作

3. **规则层向主线 A 植入退出提示信息**
   - 规则层在检测到支线B的should_exit信号后，不直接退出
   - 而是向主线A添加退出提示词，使其进入收尾阶段
   - 主线A根据提示词调整回复内容和节奏，逐步引导对话走向结束

4. **规则层基于主线 A 的退出标记做出最终决策**
   - 规则层持续监测主线 A 的输出，当检测到 exit=true 时
   - 做出最终的退出决策，正式结束当前 ai_say 过程

##### 支线 B 的深度评估机制

支线 B 作为分析层，承担着深度评估用户状态的重要职责，评估的具体维度和标准由领域提示词定义：

```json
{
  "should_exit": false,
  "exit_reason": null,
  "assessment_summary": [
    "理解度：75分，较好",
    "接受度：68分，一般",
    "抗拒程度：3分，较低",
    "表达了理解意图"
  ],
  "progress_summary": "已完成ABC模型的基本介绍，用户表现出较好的理解。",
  "strategy_prompt": "用户已基本理解ABC模型，建议进行简要总结并询问是否有进一步问题。",
  "detailed_assessment": {
    "understanding_level": 75,
    "acceptance_level": 68,
    "resistance_score": 3,
    "expresses_understanding": true,
    "identified_questions": []
  }
}
```

评估的关键维度包括但不限于：
- **理解度**(understanding_level)：0-100分量化用户对当前话题的理解程度
- **接受度**(acceptance_level)：用户对所学内容的接受程度
- **抗拒程度**(resistance_score)：用户表现出的抗拒或阻抗程度
- **表达理解意图**(expresses_understanding)：用户是否明确表达了理解
- **疑问识别**(identified_questions)：是否还有未解答的疑问

> **注意**：具体的评估维度、权重和判断标准都由领域提示词定义，而非在规则层硬编码。规则层只关注支线B的最终决策结果should_exit。

##### 规则层的决策逻辑

规则层基于支线 B 的评估结果和主线 A 的退出标记进行决策判断：

```typescript
function evaluateExitDecision(
  branchBAssessment: BranchBAssessment,
  mainLineOutput: MainLineOutput,
  context: AiSayContext
): ExitDecision {
  // 兜底保护：最大轮次限制（优先级最高）
  if (context.currentRound >= context.maxRounds) {
    return { 
      shouldExit: true, 
      reason: "max_rounds_reached" 
    };
  }
  
  // 主要依据：主线A标记退出时才真正退出
  if (mainLineOutput.exit === true) {
    return {
      shouldExit: true,
      reason: mainLineOutput.exit_reason || "mainline_a_exit_signal"
    };
  }
  
  // 支线B建议准备退出时，向主线A添加退出提示词
  if (branchBAssessment.should_exit) {
    return {
      shouldPrepareExit: true,
      action: "add_exit_prompt_to_mainline",
      reason: branchBAssessment.exit_reason || "branch_b_recommended_exit"
    };
  }
  
  // 其他情况继续对话
  return {
    shouldContinue: true,
    reason: "branch_b_not_ready_to_exit"
  };
}
```

规则层的关键决策点：
1. **信任主线A的最终判断**：只有当主线A标记exit=true时，规则层才做出最终退出决策
2. **准备退出阶段**：当支线B建议退出时，规则层向主线A添加退出提示词，不直接退出
3. **最终退出阶段**：当主线 A 根据退出提示词生成了总结性回复并标记 exit=true 时，规则层做出最终退出决策

##### 主线 A 的收尾响应机制

当规则层决定准备退出并向主线 A 添加退出提示词后，主线 A 会调整其回复策略：

```json
{
  "response": {
    "咨询师": "看起来你已经很好地理解了ABC模型的核心概念。我们可以简单回顾一下：A代表诱发事件，B代表信念，C代表结果。它们之间的关系是重要的理解点。你现在还有什么想进一步探讨的吗？"
  },
  "exit": true,
  "exit_reason": "comprehensive_understanding_demonstrated"
}
```

主线 A 在收尾阶段的特点：
1. **内容调整**：从知识讲解转为总结回顾
2. **节奏变化**：引导对话走向结束
3. **出口标识**：在适当时候标记 exit=true

> **注意**：主线A标记exit=true是对话自然收尾的结果，而非规则层直接命令其退出。规则层通过监测这个标记来做出最终的退出决策。

##### 完整协作流程示例

以下是一个完整的协作流程示例：

```
第1轮: 用户输入问题
  ↓
支线B分析: should_exit=false, understanding_level=65, expresses_understanding=false
  ↓
规则层决策: 继续对话
  ↓
主线A回复: 继续详细讲解

... 几轮对话后 ...

第N轮: 用户表示"我大概明白了"
  ↓
支线B分析: should_exit=true, exit_reason="understanding_achieved", understanding_level=75, expresses_understanding=true
  ↓
规则层决策: 检测到should_exit=true，向主线A添加退出提示词，准备进入收尾阶段
  ↓
主线A回复: 开始总结回顾...
  ↓
第N+1轮: 主线A根据提示词继续总结...
  ↓
第N+2轮: 主线A标记exit=true
  ↓
规则层决策: 检测到exit=true，正式退出
```

这种协作机制的优势在于：
1. **职责分明**：支线B负责复杂的评估判断，规则层负责决策和流程控制
2. **渐进式退出**：避免突然中断，提供自然的对话结束体验
3. **决策可靠性**：通过多个信号源确认退出时机，提高决策准确性
4. **高度可配置**：评估维度和标准都可通过提示词调整，无需修改代码

#### 核心思路

**问题**：LLM 可能出现重复回答、理解度停滞等异常
**方案**：支线 B（LLM）每轮监控对话质量，规则层基于监控结果做流程控制

#### 支线 B 输出格式

```typescript
interface BranchBAssessment {
  // 退出决策
  should_exit: boolean;
  exit_reason?: string;
  
  // 评估摘要
  assessment_summary: string[];
  
  // 进度总结
  progress_summary: string;
  
  // 策略提示
  strategy_prompt: string;
  
  // 详细评估数据（根据提示词定义的维度）
  detailed_assessment: Record<string, any>;
}
```

#### 规则层应对策略

```typescript
function evaluateExitRules(
  branchBAssessment: BranchBAssessment, // 支线 B 输出
  mainLineOutput: MainLineOutput,        // 主线 A 输出
  context: AiSayContext
): ExitDecision {
  // 🛡️ 硬兜底：最大轮次（优先级最高）
  if (context.currentRound >= context.maxRounds) {
    return {
      shouldExit: true,
      exitReason: "max_rounds_reached",
      note: "达到最大轮次，强制退出",
    };
  }

  // 主要依据：主线A标记退出时才真正退出
  if (mainLineOutput.exit === true) {
    return {
      shouldExit: true,
      exitReason: mainLineOutput.exit_reason || "mainline_a_exit_signal",
      note: "主线A标记退出，正式退出ai_say",
    };
  }

  // 支线B建议准备退出时，向主线A添加退出提示词
  if (branchBAssessment.should_exit) {
    return {
      shouldPrepareExit: true,
      action: "add_exit_prompt_to_mainline",
      exitReason: branchBAssessment.exit_reason || "branch_b_recommended_exit",
      note: "支线B建议准备退出",
    };
  }

  // 默认继续对话
  return { 
    shouldContinue: true, 
    action: "continue" 
  };
}
```

#### 配置建议

```yaml
# 支线 B 配置
branch_b:
  enabled: true
  run_every_round: true # 每轮都运行
  # 评估维度和标准由提示词定义

# 硬兜底配置
safety_limits:
  max_rounds: 10 # 最大轮次（硬限制）
```

#### 关键优势

1. **LLM 做复杂评估**：负责所有语义识别和多维度评估
2. **规则做简单决策**：基于支线 B 的结论进行退出决策
3. **硬兜底保障**：最大轮次确保系统不会无限循环
4. **高度可配置**：评估维度和标准都可通过提示词调整

---

### 4.4 六大中止场景（核心）

| 中止场景           | 临床表现                         | 识别机制                            | 优先级    | 应对策略                   |
| ------------------ | -------------------------------- | ----------------------------------- | --------- | -------------------------- |
| **来访者阻抗**     | 回避语言、防御情绪、对抗表达     | 阻抗评分 ≥ 7 或连续 2 轮 ≥ 5        | 🔴 高     | 探索阻抗原因               |
| **认知准备度不足** | 反复无法理解、混淆概念、无法举例 | 认知准备度 ≤ 3 且 3 轮后理解度 < 40 | 🟡 中     | 降低难度或跳过             |
| **情绪耐受力超载** | 情绪激动、哭泣、认知混乱         | 情绪强度 ≥ 8/10                     | 🔴 高     | 情绪稳定化                 |
| **话题依赖性判断** | 理解度低 + 下一话题依赖当前话题  | 查询话题依赖关系图                  | 🟡 中     | 必需 → 坚持，非必需 → 跳过 |
| **时间收益权衡**   | 理解度提升缓慢、边际收益递减     | 轮次 ≥ maxRounds + 收益 = low       | 🟢 低     | 记录跟进                   |
| **发现紧急问题**   | 自杀意念、自伤行为、危机事件     | 风险等级 = 高                       | 🔴🔴 最高 | 立即危机干预               |

**话题依赖关系示例**：

```
ABC 模型（必需）
  ↓
自动化思维识别（必需）
  ↓
思维记录（必需）
  ↓
认知重构（必需）
  ↓
行为实验（可选）
```

### 4.4 综合决策流程（退出 + 中止）

**决策优先级**：

```
1. 检查中止条件（优先级更高）
   ├─ 危机检测 → 立即中止
   ├─ 情绪超载 → 立即中止
   ├─ 强烈阻抗 → 立即中止
   ├─ 认知准备度不足 → 根据必要性决定
   └─ 时间收益低 → 根据必要性决定

2. 检查退出条件（成功完成）
   ├─ 理解度达标 → 自然退出
   ├─ 用户明确表示理解 → 自然退出
   └─ 最大轮次 → 强制退出

3. 继续对话
   └─ 继续讲解或回答疑问
```

**核心设计原则**：

- 🔴🔴 **安全优先**：危机 > 所有其他目标
- 🔴 **治疗联盟优先**：关系 > 技术
- 🟡 **个体化**：认知准备度因人而异
- 🟡 **目标导向**：必需话题 vs 非必需话题
- 🟢 **效率**：时间有限，需要权衡

### 4.5 自然过渡实现（基于 phase/topic/action 的层级推断）

#### 问题与总体思路

**问题**：LLM 不知道“要从哪里退”“要退到哪里去”，在退出当前 ai_say 时，容易自己编造下一步（"我们来做个练习吧"），与脚本编排冲突，也容易显得机械、每次都来一段固定过渡话术。

**总体思路**：

- 充分利用脚本本身已有的 **会谈结构层级**：`phase → topic → action`；
- **完全取消脚本侧的 transition_mode 等人工标注**，CBT 工程师只负责定义内容（phase/topic/actions）；
- 由引擎在退出当前 ai_say 后，
  - 根据“当前节点 → 下一个节点”的层级关系，自动推断过渡等级；
  - 决定是使用**显性过渡模板**、**轻量过渡模板**，还是**不额外插入过渡**。

对应三种自然过渡形式：

1. **Phase 级过渡（显性，explicit）**  
   - 场景：从一个阶段结束，进入**新 phase** 的第一个 topic／action；
   - 形式：2–3 句完整过渡（肯定 + 小结 + 明确告知“接下来这一大段要做什么”）；
   - 用途：帮助来访者清楚地感知“这一大块讲完了，我们要进入新的阶段”。

2. **Topic 级过渡（轻量，light）**  
   - 场景：phase 不变，但 topic 发生变化；
   - 形式：0–2 句**很短的衔接语**（如“接下来我想用一个例子具体说明…”），也允许根据上下文直接切入；
   - 用途：让对话感觉连贯，而不是每次都庄重宣布“我们换个话题”。

3. **Action 级切换（无显式过渡，none）**  
   - 场景：同一 topic 里的多个 action（如两个 ai_say 连在一起，或 ai_say → ai_ask）；
   - 形式：**不额外生成专门的过渡句**，只依赖：
     - 对话上下文窗口（recent_chat_window / chat_with_latest_message）；
     - 支线 B 输出来的 strategy_prompt / progress_summary；
   - 用途：让同一小话题内部的轮次切换更像自然聊天，而不是每一步都“隆重宣告”。

在此基础上，仍然保留“脚本预定义话题说明 + 运行时变量替换 + 晚注入”这一主线，但把“**过渡形式选择**”从脚本配置迁移到 **引擎对 phase/topic/action 层级的自动推断** 上。

---

#### 三阶段过渡机制（引擎侧自动决定显性/轻量/无）

##### 阶段 1：脚本预定义话题说明

为每个 action （ai_say / ai_ask / ai_think）增加 `topic_summary` 字段（一句话话题说明）：

```yaml
- action: ai_ask
  topic: "自动化思维识别"
  topic_summary: "让用户谈一下{情绪问题}对生活影响" # ← 可包含变量
  content: |
    按下面要求引导用户谈一下{情绪问题}对生活影响...
```

**编写规则**：

- 长度 ≤20 字，只描述"做什么"
- 可包含 `{变量名}`，运行时替换
- 禁止包含步骤、指令、目标变量名

**自动生成**：在 CounselingScript 聚合根创建时，如果未显式指定 `topic_summary`，自动调用 LLM 批量生成（一次调用处理多个 action，成本低）。

---

##### 阶段 2：运行时变量替换

在退出时，使用 PromptTemplateService 替换话题说明中的变量：

```typescript
// 脚本定义：topic_summary = "让用户谈一下{情绪问题}对生活影响"
// 运行时：context.getVariable('情绪问题') = '焦虑'
// 替换后：resolvedSummary = "让用户谈一下焦虑对生活影响"
```

---

##### 阶段 3：退出后准备 NextActionCue + 下一 action 首轮注入

只有在 **EV-064 `ExitConditionEvaluated`.shouldExit === true**（即规则层已确认当前 ai_say 话题应结束）之后，才会进入自然过渡信息准备流程：

1. **根据路径推断 TransitionLevel**：
   - 如果 `next.phaseId !== current.phaseId` → `transitionLevel = 'phase'`；
   - 否则如果 `next.topicId !== current.topicId` → `transitionLevel = 'topic'`；
   - 否则 → `transitionLevel = 'action'`。

2. **构造 NextActionCue（topic + benefit + transitionLevel）**：
   - topic：使用上一节生成的、已做变量替换的极简话题说明；
   - benefit：来自脚本 `benefit` 字段或引擎内置推断（如“帮助你理解 X”“帮助我们更了解你的情况”等）；
   - transitionLevel：由上一步的 phase/topic/action 关系自动得出。

3. **为下一个 action 的首轮提示词生成开场提示**：

   - 调用 `buildTransitionOpeningHint(NextActionCue)` 得到一段**纯提示信息** `next_action_opening_hint`：
     - 当 `transitionLevel = 'phase'` 时：提示下一轮主线 A 先用 1–2 句肯定 + 小结，然后显性说明“进入新的阶段：{topic}，带来的价值是 {benefit}”；
     - 当 `transitionLevel = 'topic'` 时：提示下一轮主线 A 优先直接从新话题自然切入，仅在需要时补 0–2 句非常口语化的轻量衔接；
     - 当 `transitionLevel = 'action'` 时：返回空串，不添加任何“流程感”说明，由 recent_chat_window + strategy_prompt 自然承接。
   - Orchestrator 在**进入下一个 action 的第 1 轮**时，将 `next_action_opening_hint` 作为系统级变量（或提示词片段）注入主线 A 模板，使“过渡+正文”在一次调用内自然完成。

4. **事件记录（仅保留 EV-079）**：
   - 记录 EV-079 `NextActionCuePrepared`：
     - 包含 `topic` / `benefit` / `transitionLevel` / `next_action_opening_hint.length` 等字段；
     - 作为审计与 A/B 测试的观测点（例如比较显性 vs 轻量过渡对用户留存的影响）；
   - **不再定义 EV-080 / EV-081**：不再单独有“过渡提示词生成/过渡消息展示”两个事件，过渡以“下一 action 首轮开场”的形式自然出现。

##### 阶段 4：双重防护——提示词禁止 + 引擎侧文本过滤

为了避免 LLM 在当前 ai_say 结束时“剧透下一步要做什么”，同时又不增加额外 LLM 调用，采用**双重防护机制**：

1. **提示词层硬约束（主线 A 模板）**：
   - 在所有主线 A 模板（包括带过渡开场提示的首轮模板）中，显式加入禁止条款，例如：
     - “只总结本轮内容和当前这一阶段/话题，不要说明后面还要做什么环节或作业”；
     - “不要使用‘下一步…’、‘接下来我们会…’、‘然后我会带你…’这类句式来预告后续流程”。
   - 对于带有 `next_action_opening_hint` 的首轮模板，约束其**只描述“当前要进入的这一阶段/话题本身”**，不解释之后还会有哪些模块。

2. **引擎层本地正则过滤（无额外 LLM 调用）**：
   - 在发送主线 A 输出给用户之前，调用 `sanitizeNextStepPhrases` 进行本地字符串处理：
     - 针对当前会话语言（如 `zh-CN`）维护一组常见“流程剧透”句式的正则表达式；
     - 对匹配到的句子做**整句裁剪或弱化**，不重新生成文本；
     - 默认覆盖高频表达，如“接下来我们会…/下一步我们要…/Then we will…” 等。
   - 该过滤逻辑不依赖 LLM，开销可以忽略；同时仍然保守：只处理最典型的剧透句式，其余更隐晦的表达交给提示词约束和脚本结构来控制。

3. **与脚本层职责的划分**：
   - 脚本作者只负责定义：
     - phase/topic/action 结构；
     - 每个 action 的 `topic_summary` 与 `benefit`；
   - 引擎负责：
     - 自动推断 TransitionLevel；
     - 构造 NextActionCue + `next_action_opening_hint`；
     - 对所有主线 A 输出统一应用“剧透句式裁剪”。

> 📘 **完整实现代码**：参见 [实现细节参考文档 §3.2](./015-ai_say智能实现细节参考.md#32-自然过渡实现)

> 📘 **退出与中止机制详细实现**：
>
> - 退出机制：参见 [实现细节参考文档 §3](./015-ai_say智能实现细节参考.md#第三部分退出机制详细实现)
> - 中止机制：参见 [实现细节参考文档 §4](./015-ai_say智能实现细节参考.md#第四部分中止机制详细实现)

---

## 第五部分：实施路线图

### 5.1 分阶段实施计划

#### Phase 1：基础实现（立即可做）

**目标**：实现可观测的三层架构

**任务**：

1. ✅ 实现三层架构的基础框架

   - 第一层：话题特定层（脚本内容 + 变量替换）
   - 第二层：通用基础设施层（系统模板 + 变量管理）
   - 第三层：流程编排层（规则验证 + 决策记录）

2. ✅ 实现可观测的决策循环

   - LLM 输出结构化推理（reasoning + response）
   - 规则层基于推理做决策
   - 记录完整的决策轨迹

3. ✅ 实现主线 A（含风险识别）
   - 一次 LLM 调用完成：推理 + 回复 + 风险识别
   - 发送前检查风险等级

**验收标准**：

- [ ] LLM 能够准确评估理解度（准确率 ≥ 80%）
- [ ] 规则层能够正确判断退出条件
- [ ] 决策轨迹完整记录

#### Phase 2：安全增强（短期可做）

**目标**：实现风险防控机制

**任务**：

1. ✅ 实现支线 C（审核修正）

   - 条件触发（只在高风险时）
   - 串行执行（确保安全）
   - 记录修正日志

2. ✅ 优化风险识别的准确性

   - 细化风险类型和等级
   - 减少误报和漏报
   - 建立风险识别的评估体系

3. ✅ 实现监控和日志系统
   - 记录每次决策的完整上下文
   - 监控风险识别准确率
   - 监控支线 C 触发率

**验收标准**：

- [ ] 虚假理解检测准确率 ≥ 90%
- [ ] 风险识别准确率 ≥ 85%
- [ ] 退出决策合理性 ≥ 90%

#### Phase 3：智能优化（中期可做）

**目标**：实现持续优化机制

**任务**：

1. ✅ 实现支线 B（策略分析）

   - 异步后台分析
   - 优化下一轮对话的沟通策略
   - 跨会话学习

2. ✅ 建立数据闭环

   - 分析决策数据，发现问题
   - 优化 prompt 模板
   - 改进规则阈值
   - 持续提升系统质量

3. ✅ 实现 A/B 测试框架
   - 测试不同的 prompt 版本
   - 测试不同的规则阈值
   - 基于数据选择最优方案

**验收标准**：

- [ ] 个性化退出阈值提升效果 ≥ 10%
- [ ] A/B 测试找到最优方案
- [ ] 持续学习机制运行稳定

### 5.2 关键成功因素（Andrew Ng 的 AI 落地经验）

**技术层面**：

- ✅ **可观测性优先**：先建立可观测性，再优化准确性
- ✅ **LLM + 规则分工明确**：LLM 做推理和策略生成，规则做流程控制
- ✅ **结构化输出**：LLM 输出 reasoning + response
- ✅ **记录决策轨迹**：每次决策都有完整记录
- ✅ **提示词工程优先**：通过优化提示词而非修改代码来快速迭代 ⭐
- ✅ **让 AI 做它擅长的事**：上下文理解、综合推理、自然语言生成 ⭐

**产品层面**：

- ✅ **平衡速度和质量**：大多数对话快速响应，高风险才审核
- ✅ **平衡安全和体验**：规则保证安全，LLM 保证智能
- ✅ **持续优化**：基于数据闭环，不断改进
- ✅ **用户反馈**：收集反馈，验证假设
- ✅ **端到端策略生成**：避免硬编码规则映射，提升灵活性 ⭐

**运营层面**：

- ✅ **监控关键指标**：
  - LLM 推理质量（理解度评分准确性、风险识别准确率）
  - **策略生成质量**（策略建议的有效性、用户满意度）⭐
  - 规则决策质量（规则覆盖率、误判率）
  - 用户体验（响应速度、满意度）
- ✅ **定期分析数据**：
  - 哪些场景下 LLM 和规则有分歧？
  - 哪些 prompt 效果最好？
  - **哪些策略建议最有效？**⭐
  - 哪些规则阈值需要调整？
- ✅ **持续迭代优化**：
  - 每周分析数据，发现问题
  - 每月优化 prompt（**包括支线 B 的策略生成提示词**）⭐
  - 每季度评估整体效果

**Andrew Ng 的核心洞察**：

> _"提示词工程是新时代的'编程'。好的提示词比复杂的规则引擎更强大、更灵活、更易维护。"_
>
> _"在 AI 时代，快速迭代的能力比完美的初始设计更重要。通过提示词优化，我们可以在几小时内完成过去需要几周的代码修改。"_

### 5.3 避免的常见陷阱

**❌ 陷阱 1：让 LLM 直接控制流程**

```typescript
// ❌ 错误：直接采纳 LLM 的决策
if (llmOutput.action === "transfer_to_safety") {
  transferToSafety(); // 危险！LLM 可能出错
}

// ✅ 正确：规则验证后再决策
const decision = evaluateRules(llmOutput.reasoning, context);
if (decision.risk_level > THRESHOLD) {
  transferToSafety(); // 安全！规则保证
}
```

**❌ 陷阱 2：没有可观测性**

```typescript
// ❌ 错误：只记录最终结果
logger.info("AI response sent");

// ✅ 正确：记录完整的决策过程
logger.info("AI Decision", {
  llm_reasoning: reasoning,
  rule_decision: decision,
  final_action: action,
  context: contextSnapshot,
});
```

**❌ 陷阱 3：过度设计**

```typescript
// ❌ 错误：为每个场景写复杂的逻辑
if (scenario === "ABC_model") {
  // 复杂的 ABC 模型逻辑
}

// ✅ 正确：通过变量和 prompt 实现
const prompt = buildPrompt(topic, variables);
const reasoning = await callLLM(prompt);
const decision = evaluateRules(reasoning);
```

**❌ 陷阱 4：过度依赖规则映射策略** ⭐

```typescript
// ❌ 错误：硬编码大量规则映射
const strategyRules = {
  high_emotion_low_education: {
    language_style: "simple",
    example_type: "concrete",
    empathy_level: "high",
  },
  low_emotion_high_education: {
    language_style: "formal",
    example_type: "abstract",
    empathy_level: "medium",
  },
  // ... 100+ 条规则
};

function selectStrategy(userProfile) {
  const key = `${userProfile.emotion}_${userProfile.education}`;
  return strategyRules[key] || DEFAULT_STRATEGY; // 脆弱！
}

// ✅ 正确：让 LLM 端到端生成策略
const strategyPrompt = await supportLineB.generateStrategy({
  userProfile,
  conversationHistory,
  currentContext,
});
// LLM 综合考虑所有因素，生成自然语言策略建议
```

**为什么端到端策略生成更好？**

- ✅ **灵活性**：LLM 可以处理 100+ 维度的组合，规则无法穷尽
- ✅ **可维护性**：只需维护 2-3 个提示词，而非 100+ 条规则
- ✅ **适应性**：LLM 可以处理边缘情况和未预见的情况
- ✅ **迭代速度**：调整提示词几小时，修改规则几周
- ✅ **符合 AI 时代设计哲学**：让 AI 做它擅长的事情

---

## 总结

### 核心架构优势

| 优势维度     | 说明                                                           |
| ------------ | -------------------------------------------------------------- |
| **清晰性**   | 三层架构，每层职责明确，边界清晰                               |
| **可观测性** | 记录完整决策轨迹，持续优化                                     |
| **可控性**   | 规则层保证关键决策的正确性；策略 → 步骤 → 话术分层保证执行可控 |
| **智能性**   | LLM 提供灵活的推理和适配能力；支线 B 动态调整策略步骤          |
| **可扩展性** | 关注点分离，易于添加新功能                                     |
| **平衡性**   | 在可控性与智能性之间找到最佳平衡点                             |

### 实施原则

1. **可观测性优先**：先能看到问题，再优化准确性
2. **安全性保障**：规则层保证关键决策的正确性
3. **持续迭代**：基于数据不断优化
4. **渐进式实现**：从简单到复杂，逐步增强智能性

### 下一步行动

1. 阅读 [实现细节参考文档](./015-ai_say智能实现细节参考.md) 了解完整代码实现
2. 按照 Phase 1 → Phase 2 → Phase 3 的顺序实施
3. 建立可观测性系统，收集数据
4. 基于数据持续优化 prompt 和规则
5. 重点关注第七部分的策略步骤执行机制

---

## 第六部分：核心设计决策与优化方向

> **设计思想来源**：Andrew Ng（吴恩达）的 AI 工程最佳实践

本部分回答三个关键设计问题，这些问题的答案构成了 ai_say 智能实现机制的核心设计决策。

---

### 6.1 LLM 评分准确性优化

#### 设计挑战

**问题**：如何让 LLM 的理解度评分更准确？

这是退出机制的核心问题。LLM 的评分如果不准确，会导致：

- **过早退出**：用户还没理解就退出，影响治疗效果
- **过晚退出**：用户已经理解但继续讲解，浪费时间
- **评分不一致**：同样的回复在不同对话中得到不同评分

#### 优化方案

我们提供 4 个优化方案，按照实施阶段递进：

##### 方案 A：Few-Shot Prompting with Anchors（Phase 1 推荐）

**核心思想**：在提示词中提供**锚点案例**，让 LLM 理解评分标准。

**关键要素**：

- 提供 4 个锚点案例（90 分、60 分、30 分、10 分）
- 分维度评分（概念复述、关系理解、举例能力、应用意识）
- 每个维度 0-25 分，总分 0-100 分

**优点**：

- ✅ 成本可控（提示词增加约 200 tokens）
- ✅ 准确性足够（锚点案例提供明确参考）
- ✅ 可解释性强（分维度评分）

**缺点**：

- ❌ 提示词变长（但可以接受）

**详细实现**：参见 [实现细节参考文档 §7.1](./015-ai_say智能实现细节参考.md#71-few-shot-anchors-提示词模板完整版)

---

##### 方案 B：Chain-of-Thought Scoring（Phase 2 优化）

**核心思想**：让 LLM **先分析再评分**，强制输出结构化的分析过程。

**关键要素**：

- 第一步：分析用户消息中的理解信号（复述、解释、举例、应用）
- 第二步：识别困惑信号（疑问、困惑、混淆）
- 第三步：综合评分

**优点**：

- ✅ 可解释性极强（完整的推理过程）
- ✅ 减少随意性（强制分析）
- ✅ 可用于后续优化（分析数据可用于改进 prompt）

**缺点**：

- ❌ 输出更长，成本稍高

**适用场景**：Phase 2 优化阶段，需要更高的可解释性时使用。

---

##### 方案 C：规则层二次校准（Phase 1 实用方案）

**核心思想**：LLM 给出初步评分后，**规则层进行二次校准**，处理边缘情况。

**关键规则**：

1. 如果用户说"明白了"但消息很短（<10 字）→ 降低可信度，上限 70
2. 如果用户举出具体例子（>30 字）→ 提升可信度，下限 75
3. 如果用户提出新问题 → 适度提升 +10
4. 如果用户表达困惑 → 降低评分 -20

**优点**：

- ✅ 成本低（纯规则处理，无额外 LLM 调用）
- ✅ 可控性强（规则明确，行为可预测）
- ✅ 快速迭代（发现新边缘情况可快速添加规则）

**缺点**：

- ❌ 需要维护规则

**详细实现**：参见 [实现细节参考文档 §7.2](./015-ai_say智能实现细节参考.md#72-规则层校准函数实现)

---

##### 方案 D：多模型投票（Phase 3 高级方案）

**核心思想**：使用多个模型或多次采样，通过投票提升准确性。

**实现方式**：

- 多次采样：同一提示词调用 3 次，取中位数
- 多模型投票：用不同模型（GPT-4, Claude, Gemini）评分，取平均值
- 后处理校准：收集人工标注数据，训练校准模型

**优点**：

- ✅ 准确性最高

**缺点**：

- ❌ 成本高（3-5 倍）
- ❌ 延迟高（串行调用）

**适用场景**：仅在关键场景使用（如必需话题的理解度评估）。

---

#### 推荐实施路线图

| 阶段                | 方案组合        | 目标                             |
| ------------------- | --------------- | -------------------------------- |
| **Phase 1（MVP）**  | 方案 A + 方案 C | 成本可控、准确性足够、快速上线   |
| **Phase 2（优化）** | 方案 B          | 提升可解释性、收集优化数据       |
| **Phase 3（高级）** | 方案 D          | 仅在关键场景使用，追求极致准确性 |

---

### 6.2 话题必要性判断机制

#### 设计挑战

**问题**：话题的必要性和重要性，应该在脚本中配置，还是让 LLM 智能判断？

这是中止机制的核心问题。不同话题的必要性不同：

- **必需话题**（critical）：ABC 模型、自动化思维识别、思维记录 → 必须理解
- **重要话题**（high）：认知歪曲识别、核心信念修正 → 建议理解
- **可选话题**（medium/low）：行为实验、情绪调节技术 → 可以跳过

#### 设计决策：混合方案（配置为主，LLM 为辅）

**核心原则**：

1. ✅ **脚本配置是基础**（CBT 专家的专业判断最可靠）
2. ✅ **规则层调整是主要手段**（明确、可控、可预测）
3. ✅ **LLM 建议是参考**（仅在高置信度时采纳）

#### 脚本配置示例

```yaml
# ai_say 脚本示例
action: ai_say
topic: "ABC 模型"
content: |
  ABC 模型是 CBT 的核心概念...

# 话题元数据（新增）
topic_metadata:
  necessity: "critical" # critical | high | medium | low
  importance: 9 # 1-10，重要性评分
  is_prerequisite_for: # 后续依赖此话题的其他话题
    - "自动化思维识别"
    - "认知重构"
  max_retry_rounds: 5 # 如果是 critical，允许更多轮次
  fallback_strategy: "schedule_review" # 如果失败，后续策略
```

#### 动态调整规则

规则层根据用户状态和会谈上下文动态调整必要性：

**规则 1**：用户认知能力 < 5 且话题是 critical → 降级为 high

- **原因**：认知能力较弱的用户可能无法理解复杂概念，强推会导致挫败感

**规则 2**：用户情绪强度 > 7 且话题非 critical → 降级

- **原因**：情绪不稳定时，认知资源有限，应优先处理情绪稳定

**规则 3**：紧急干预场景 → 只保留 critical 话题

- **原因**：紧急干预时，时间和资源有限，必须聚焦最关键的内容

**详细实现**：参见 [实现细节参考文档 §7.3](./015-ai_say智能实现细节参考.md#73-话题必要性动态判断实现)

---

### 6.3 ai_say 架构设计决策

#### 设计问题

**问题**：ai_say 是否应该拆分成多个 action（如 ai_introduce、ai_persuade、ai_suggest）？

咨询师的主动表达有多种场景：

- **介绍概念**：讲解 CBT 理论、技术
- **说服用户**：说服用户尝试某个技术、接受某个观点
- **介绍方案**：介绍治疗计划、作业安排

这些场景是否需要不同的 action？

#### 设计决策：统一的 ai_say + subtype（不拆分）

**理由**：

**1. 本质相同**

- 所有场景本质都是：**咨询师主动表达 + 用户理解/接受**
- 退出条件类似：理解度达标、接受度达标、阻抗、情绪超载等
- 智能机制类似：LLM 推理 + 规则验证

**2. 避免过度设计**

- 如果拆分成 ai_introduce、ai_suggest、ai_persuade，会导致：
  - 代码重复（90% 的逻辑是相同的）
  - 维护成本高（修改一个功能需要改多处）
  - 脚本作者困惑（什么时候用哪个？边界不清晰）

**3. 灵活性更高**

- 通过 **subtype** 区分场景，而不是创建新 action
- 使用**策略模式**实现不同场景的定制化行为
- 核心引擎共享，策略可插拔

#### 实现方式

```yaml
# 示例 1：介绍概念
action: ai_say
subtype: introduce_concept
topic: "ABC 模型"
exit_criteria:
  understanding_threshold: 80

# 示例 2：说服用户
action: ai_say
subtype: persuade
topic: "尝试思维记录的价值"
exit_criteria:
  acceptance_threshold: 70  # 接受度而非理解度
  max_persuasion_rounds: 3

# 示例 3：介绍方案
action: ai_say
subtype: introduce_plan
topic: "我们的治疗计划"
exit_criteria:
  understanding_threshold: 70
  acceptance_threshold: 60  # 理解度 + 接受度都要达标
```

**详细实现**：参见 [实现细节参考文档 §7.4](./015-ai_say智能实现细节参考.md#74-subtype-策略模式实现)

---

## 第七部分：谈话策略与步骤执行的智能平衡

> **设计思想来源**：分层决策架构（Hierarchical Decision Making）+ 元认知监控（Meta-Cognitive Monitoring）

本部分阐述 ai_say 如何在**可控性**与**智能性**之间找到平衡，通过**策略 → 步骤 → 话术**三层架构实现既能按预定计划执行，又能根据实际情况灵活调整的智能对话系统。

---

### 7.1 设计动机：为什么需要进度与策略管理？

#### 7.1.1 核心挑战

**问题 1：复杂智能介绍的可控性**

- CBT 概念介绍往往包含多个知识点（如 ABC 模型包含：定义、三要素、因果关系、案例、应用）
- 如果没有明确的进度跟踪，LLM 可能：
  - ❌ 重复讲解已经讲过的内容
  - ❌ 遗漏重要知识点
  - ❌ 无法判断"讲到哪里了"
  - ❌ 难以决定"何时可以退出"

**问题 2：可控性与智能性的矛盾**

- **纯脚本化**（完全预定义步骤）：

  - ✅ 可控性强：每一步都明确
  - ❌ 智能性弱：无法适应用户个体差异
  - ❌ 用户体验差：机械、不灵活

- **纯 LLM 自由发挥**：
  - ✅ 智能性强：能适应用户
  - ❌ 可控性弱：难以保证质量
  - ❌ 不可预测：可能偏离主题或遗漏要点

**问题 3：咨询师经验的表达**

- 资深咨询师知道"在什么情况下做什么事"
- 但这种经验是有限的，无法穷尽所有情况
- 需要一种机制：既能利用咨询师经验，又能让 AI 在经验之外灵活应对

#### 7.1.2 设计目标

**目标 1：清晰的进度可视化**

- 用户知道："我在哪里？还剩什么？"
- 咨询师知道："讲到第几步了？下一步是什么？"
- 系统知道："何时可以退出？何时需要调整？"

**目标 2：可控性与智能性的平衡**

- **基线质量保证**：预定义的策略步骤确保不遗漏要点
- **动态适应能力**：根据用户理解情况调整步骤顺序和深度
- **可追溯性**：每一步的执行都有记录，便于调试和优化

**目标 3：咨询师经验的有效利用**

- **主线 A**：按预定义的策略步骤执行（咨询师经验）
- **支线 B**：持续观察对话，在必要时调整策略（AI 智能）
- **规则层**：确保调整在合理范围内（安全兜底）

---

### 7.2 核心设计：策略 → 步骤 → 话术三层架构

#### 7.2.1 架构定义

```
┌─────────────────────────────────────────────────────────┐
│ 策略层（Strategy Layer）                                 │
│ • 职责：定义"做什么"（What to do）                        │
│ • 来源：脚本预定义 + 支线 B 动态调整                      │
│ • 例子：介绍 ABC 模型的整体策略                           │
│ • 可调整：支线 B 可根据用户情况调整策略                   │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│ 步骤层（Steps Layer）                                    │
│ • 职责：定义"怎么做"（How to do）                        │
│ • 来源：支线 B 规划 + 动态调整                            │
│ • 例子：1.定义 → 2.要素 → 3.关系 → 4.案例 → 5.应用      │
│ • 可调整：根据用户理解度动态增删步骤                      │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│ 话术层（Utterance Layer）                                │
│ • 职责：生成具体的对话内容                                │
│ • 来源：主线 A 根据当前步骤生成                           │
│ • 例子："ABC 模型是 CBT 的核心概念..."                   │
│ • 可调整：根据用户语言风格、理解能力调整表达              │
└─────────────────────────────────────────────────────────┘
```

#### 7.2.2 分层职责

**策略层**：

- **定义**：包含两个维度
  - **话题目标**（What）：要达成什么目标（脚本预定义）
  - **沟通策略**（How）：如何达成目标（支线 B 端到端生成）⭐
- **示例**：
  - **话题目标**："介绍 ABC 模型的核心概念"（脚本预定义，不变）
  - **沟通策略**：
    ```
    语言风格：半正式、中等复杂度、委婉
    例子类型：具体的个人经历例子
    共鸣策略：高强度情绪验证 + 普遍化
    引导方式：反思引导为主
    ```
    （支线 B 端到端生成，动态调整）
- **来源**：
  - **话题目标**：脚本预定义（咨询师经验）
  - **沟通策略**：支线 B 端到端生成（无需规则映射）

**步骤层**：

- **定义**：将话题目标拆解为可执行的步骤序列
- **示例**（介绍 ABC 模型）：
  ```
  1. 介绍 ABC 模型定义
  2. 解释三要素（A/B/C）
  3. 说明因果关系
  4. 举实际案例
  5. 引导用户举自己的例子
  ```
- **来源**：
  - 支线 B 基于主题提示词规划
  - 根据用户理解情况动态调整（增删步骤、调整顺序）

**话术层**：

- **定义**：每一轮对话的具体内容
- **示例**：
  ```
  "ABC 模型是认知行为疗法的核心概念。A 代表诱发事件（Activating event），
  B 代表信念（Belief），C 代表结果（Consequence）。这三者之间有着密切的关系..."
  ```
- **来源**：
  - 主线 A 根据当前步骤、用户背景、**支线 B 生成的沟通策略**生成

**关键区分**：

- ✅ **话题目标**（What）：脚本预定义，体现咨询师专业判断
- ✅ **沟通策略**（How）：支线 B 端到端生成，体现 AI 灵活适配
- ✅ **无需规则映射**：沟通策略是自然语言，主线 A 可以直接理解和应用

---

### 7.3 双线程协作机制

#### 7.3.1 主线 A：按步执行

**职责**：

- 接收支线 B 规划的当前步骤信息
- 根据步骤生成具体的对话内容
- 识别用户理解度、疑问、风险等基础状态

**输入**（来自支线 B）：

```typescript
{
  current_step_index: 3,           // 当前在第 3 步
  total_steps: 5,                  // 总共 5 步
  step_description: "说明因果关系", // 当前步骤描述
  next_step_focus: "举实际案例，帮助用户理解应用", // 下一步重点
  progress_summary: "已讲解：ABC 模型定义、三要素 | 剩余：因果关系、案例、应用"
}
```

**输出**：

```typescript
{
  response: "咨询师的回复内容...",
  reasoning: {
    understanding_level: 75,
    identified_questions: ["A 和 B 的关系是什么？"],
    risk_assessment: { level: "low" }
  }
}
```

**关键点**：

- ✅ 主线 A 专注于**当前步骤**的执行
- ✅ 不需要关心"整体进度"和"下一步规划"（由支线 B 负责）
- ✅ 任务简化，响应速度快（2-3 秒）

#### 7.3.2 支线 B：动态监控与调整

**职责**：

- 分析完整对话历史，识别已讲解和剩余内容
- 规划讲解步骤，识别当前在第几步
- 根据用户理解情况，动态调整步骤
- 为下一轮主线 A 提供步骤信息

**输入**：

```typescript
{
  full_chat_history: [...],        // 完整对话历史
  topic_prompt: "...",             // 主题提示词
  last_main_line_output: {...}     // 上一轮主线 A 的输出
}
```

**输出**：

```typescript
{
  // 进度分析
  progress_analysis: {
    covered_topics: ["ABC 模型定义", "三要素（A/B/C）"],
    remaining_topics: ["因果关系", "实际案例", "用户例子"],
    current_step: "3/5",
    completion_percentage: 40,
    progress_summary: "已讲解：定义、要素 | 剩余：关系、案例、应用"
  },

  // 策略步骤规划
  strategy_steps: {
    planned_steps: [
      "1. 介绍 ABC 模型定义",
      "2. 解释三要素（A/B/C）",
      "3. 说明因果关系",
      "4. 举实际案例",
      "5. 引导用户举自己的例子"
    ],
    current_step_index: 3,
    step_description: "说明因果关系",
    next_step_focus: "举实际案例，帮助用户理解应用",
    adjustment_reason: null  // 如果调整了步骤，说明原因
  }
}
```

**关键点**：

- ✅ 支线 B 异步执行，不阻塞当前回复
- ✅ 持续分析对话历史，维护进度状态
- ✅ 根据用户理解情况动态调整步骤

#### 7.3.3 协作流程

```
用户输入
  ↓
【主线 A】根据当前步骤生成回复（2-3秒）
  ├─ 读取：current_step_index, step_description, next_step_focus
  ├─ 生成：针对当前步骤的回复
  └─ 识别：理解度、疑问、风险
  ↓
【规则层】基于主线 A 的识别结果判断
  ├─ 风险等级 = high → 触发支线 C
  ├─ 理解度 >= 80 → 可以退出
  └─ 其他 → 继续对话
  ↓
【发送给用户】
  ↓
【支线 B】异步分析 + 规划下一步（后台）
  ├─ 分析对话历史，更新进度
  ├─ 评估用户理解情况
  ├─ 决定是否调整步骤
  │   • 用户理解快 → 简化步骤（跳过详细解释）
  │   • 用户理解慢 → 增加步骤（增加例子、拆解概念）
  │   • 用户跑题 → 调整重点（先处理疑问）
  └─ 为下一轮主线 A 准备步骤信息
  ↓
【更新上下文】供下一轮使用
```

---

### 7.4 面临的挑战与解决方案

#### 7.4.1 挑战 1：策略冲突

**问题**：支线 B 调整的策略可能与脚本预定义的策略冲突

**示例**：

- 脚本预定义：必须讲解 ABC 模型的 5 个步骤
- 支线 B 建议：用户理解快，跳过第 4 步（详细案例）

**解决方案**：分级调整机制

```typescript
interface StrategyAdjustment {
  type: "minor" | "major"; // 调整幅度
  confidence: number; // 调整信心（0-1）
  override_allowed: boolean; // 是否允许覆盖脚本
}

// 规则：
// 1. minor 调整（如调整语言风格、例子选择）→ 直接应用
// 2. major 调整（如跳过步骤、改变顺序）→ 需要 confidence > 0.8
// 3. 涉及必需话题（necessity = 'critical'）→ 不允许跳过
// 4. 涉及安全/伦理 → 永远不允许覆盖
```

**详细实现**：参见 [实现细节参考文档 §7.6.4](./015-ai_say智能实现细节参考.md#764-策略冲突解决机制)

#### 7.4.2 挑战 2：步骤动态调整的时机

**问题**：何时应该调整步骤？调整太频繁会导致不稳定，调整太少会失去灵活性

**解决方案**：策略稳定性机制

```typescript
interface StrategyStability {
  min_rounds_before_change: number; // 最少执行几轮再改变（默认 2）
  change_threshold: number; // 改变阈值（避免微小波动）

  // 策略变更日志
  change_history: {
    round: number;
    old_strategy: string;
    new_strategy: string;
    reason: string;
  }[];
}

// 规则：
// 1. 新策略至少执行 2 轮再考虑调整
// 2. 调整幅度 < 阈值（如理解度变化 < 10）→ 不调整
// 3. 记录所有策略变更，便于分析和调试
```

**详细实现**：参见 [实现细节参考文档 §7.6.5](./015-ai_say智能实现细节参考.md#765-策略稳定性机制)

#### 7.4.3 挑战 3：主线 A 与支线 B 的协作边界

**问题**：主线 A 和支线 B 的职责边界在哪里？如何避免职责重叠？

**解决方案**：清晰的职责划分

| 维度           | 主线 A                  | 支线 B              |
| -------------- | ----------------------- | ------------------- |
| **执行频率**   | 每轮同步执行            | 每轮异步执行        |
| **响应时间**   | 2-3 秒（快速）          | 不限制（深度分析）  |
| **核心任务**   | 生成回复 + 基础状态识别 | 进度分析 + 策略规划 |
| **理解度评估** | 快速评估（0-100）       | 深度评估（分维度）  |
| **步骤规划**   | ❌ 不负责               | ✅ 负责             |
| **进度跟踪**   | ❌ 不负责               | ✅ 负责             |
| **策略调整**   | ❌ 不负责               | ✅ 负责             |
| **话术生成**   | ✅ 负责                 | ❌ 不负责           |

**关键原则**：

- ✅ 主线 A：专注**当前回合**的执行
- ✅ 支线 B：专注**整体进度**的规划
- ✅ 规则层：基于两者的输出做最终决策

#### 7.4.4 挑战 4：可解释性

**问题**：用户/咨询师可能不理解"为什么 AI 这样做"

**解决方案**：可解释的决策记录

```typescript
interface ExplainableDecision {
  decision: string; // 决策内容
  reasoning: {
    evidence: string[]; // 证据（如"用户连续 3 轮表示不理解"）
    rule_applied: string; // 应用的规则
    confidence: number; // 决策信心
    alternatives: string[]; // 其他可能的选择
  };
  strategy_change?: {
    from: string; // 原策略
    to: string; // 新策略
    reason: string; // 变更原因
  };
}
```

**详细实现**：参见 [实现细节参考文档 §7.6.7](./015-ai_say智能实现细节参考.md#767-可解释性增强)

---

### 7.5 核心优势总结

#### 7.5.1 可控性维度（9/10 分）

✅ **预定义步骤保证基线**

- 脚本预定义策略确保不遗漏要点
- 类似于 Curriculum Learning，先保证基础路径

✅ **进度可视化**

- 每回合明确进度（第 X/Y 步）
- 用户、咨询师、系统都知道"在哪里"

✅ **规则层兜底**

- 最大轮次限制防止无限循环
- 必需话题不允许跳过
- 安全/伦理规则永远优先

⚠️ **需要改进**

- 策略冲突解决机制需要持续优化
- 调整阈值需要基于数据调优

#### 7.5.2 智能性维度（8.5/10 分）

✅ **动态策略调整**

- 根据用户理解度调整步骤
- 用户快 → 简化；用户慢 → 增加

✅ **上下文感知**

- 支线 B 持续分析对话历史
- 识别已讲解和剩余内容

✅ **元认知监控**

- 类似人类咨询师的"第三视角"
- 持续观察、思考、调整

⚠️ **需要改进**

- 策略稳定性机制需要验证
- 可解释性需要增强

#### 7.5.3 工程可行性（9/10 分）

✅ **异步架构合理**

- 支线 B 不阻塞当前回复
- 响应速度快（2-3 秒）

✅ **接口设计清晰**

- 主线 A 和支线 B 职责明确
- 数据结构清晰

✅ **分层解耦良好**

- 策略层、步骤层、话术层分离
- 易于维护和扩展

⚠️ **需要监控**

- 支线 B 的延迟需要监控
- 策略调整的频率需要分析

---

### 7.6 实施建议

#### 7.6.1 渐进式实现路径

**Phase 1: MVP（最小可行产品）**

```typescript
// 主线 A：执行预定义步骤
// 支线 B：仅做进度分析（不调整策略）
// 规则层：硬编码步骤顺序
```

**Phase 2: 增强版**

```typescript
// 主线 A：执行预定义步骤
// 支线 B：进度分析 + 简单调整（如跳过/重复步骤）
// 规则层：基于阈值的策略调整
```

**Phase 3: 完整版**

```typescript
// 主线 A：执行预定义步骤
// 支线 B：全功能（进度、策略规划、质量监控）
// 规则层：复杂策略调整 + 冲突解决
```

**Phase 4: 优化版**

```typescript
// 主线 A：执行预定义步骤
// 支线 B：全功能 + 自学习（从历史对话中优化策略）
// 规则层：自适应阈值 + 可解释性
```

#### 7.6.2 关键成功因素

**技术层面**：

- ✅ 清晰的职责划分（主线 A vs 支线 B）
- ✅ 异步架构（不阻塞响应）
- ✅ 可观测性（记录所有决策）
- ✅ 规则兜底（防止失控）

**产品层面**：

- ✅ 从简单场景开始（如单一概念介绍）
- ✅ 收集真实对话数据
- ✅ 持续优化策略调整规则
- ✅ A/B 测试不同策略

**运营层面**：

- ✅ 监控策略调整频率
- ✅ 分析调整效果
- ✅ 收集用户反馈
- ✅ 定期评估系统质量

> 📘 **详细实现代码**：参见 [实现细节参考文档 第七部分](./015-ai_say智能实现细节参考.md#第七部分优化方案详细实现)

---

## 总结

**文档名称**：ai_say 智能实现机制（主文档）
**版本**：v3.1
**最后更新**：2025-01-12
**作者**：MoodlingVale 团队
**相关文档**：

- [ai_say 实现细节参考](./015-ai_say智能实现细节参考.md)
- [ai_say 应用场景分析](./README-ai_say.md)
- [支线 B 如何影响主线 A](./archive/关于支线B如何影响主线A.md)
- [沟通策略维度设计与实现](./016-沟通策略维度设计与实现.md)
- [LLM 资源共享与多任务优化架构](./023-llm-resource-sharing-optimization.md) - 性能优化与工程实施指南

**更新日志**：

- v3.1 (2025-01-12)：**新增支线 B 策略生成提示词模板**
  - 新增 §3.2.1 "策略生成提示词模板（完整版）"
  - 提供完整的支线 B 提示词模板，包括所有输入变量和输出格式
  - 明确四个沟通策略维度的数据源映射（语言风格、例子类型、共鸣策略、引导方式）
  - 新增"关键设计要点"部分，阐述 Andrew Ng 的端到端策略生成理念
  - 在 §2.3 和 §2.4 添加指向 §3.2.1 的交叉引用
  - 关联文档：新增《沟通策略维度设计与实现》
- v3.0 (2025-01-12)：**重大更新 - 端到端策略生成理念**
  - 新增"设计哲学"部分，引入 Andrew Ng 的核心洞察
  - 核心理念从 3 个扩展到 4 个，新增"沟通策略由 LLM 端到端生成"
  - 重构 §2.3 变量系统设计：删除预定义策略变量，改为支线 B 端到端生成策略提示词
  - 重构 §3.2 支线 B 职责：扩展为"质量监控 + 策略生成引擎"
  - 更新 §2.4 提示词设计要点：展示支线 B 生成的自然语言策略建议
  - 更新 §2.1 智能能力清单：明确"沟通策略生成"为支线 B 核心职责
  - 更新 §1.2 关键原则：强调"策略生成无需规则映射"
  - 更新 §7.2 策略层定义：区分"话题目标"（脚本预定义）vs "沟通策略"（支线 B 生成）
  - 增强 §5.2 关键成功因素：新增提示词工程和快速迭代的重要性
  - 新增 §5.3 陷阱 4：避免过度依赖规则映射策略
- v2.5 (2025-01-11)：参考文档新增 8 个智能能力详细实现（§2.6-2.11, §7.1 补充, §8），同步版本号
- v2.4 (2025-01-11)：修复交叉引用链接错误（§7.5→§7.6.4, §7.6→§7.6.5, §7.7→§7.6.7），同步版本号与参考文档
- v2.3 (2025-01-11)：新增第七部分"谈话策略与步骤执行的智能平衡"，阐述策略 → 步骤 → 话术三层架构、双线程协作机制、可控性与智能性的平衡设计
- v2.2 (2025-01-11)：重构 §4.5 自然过渡实现，改为基于 phase/topic/action 层级自动推断显性/轻量/无过渡形式，取消脚本侧 transition_mode 配置
- v2.1 (2025-01-09)：新增第六部分"核心设计决策与优化方向"，整合了退出机制设计讨论的内容
- v2.0 (2025-01-09)：拆分为主文档和参考文档，新增中止机制内容
