# ai_say Action é»˜è®¤è°ƒç”¨ LLM

## ä¿®æ”¹è¯´æ˜

**ä¿®æ”¹æ—¶é—´**: 2026-01-18

### é—®é¢˜

ä¹‹å‰ `ai_say` Action éœ€è¦æ˜¾å¼é…ç½® `use_llm: true` æ‰ä¼šè°ƒç”¨ LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€è¡¨è¾¾ï¼Œè¿™å¯¼è‡´ï¼š

1. **é…ç½®ç¹ç**ï¼šæ¯ä¸ª ai_say éƒ½éœ€è¦é¢å¤–é…ç½®
2. **è¡Œä¸ºä¸ä¸€è‡´**ï¼šæœ‰äº›è„šæœ¬è°ƒç”¨ LLMï¼Œæœ‰äº›ä¸è°ƒç”¨
3. **è®¾è®¡ä¸åˆç†**ï¼šai_say çš„æ ¸å¿ƒèŒè´£å°±æ˜¯ç”Ÿæˆ AI å›å¤ï¼Œæœ¬åº”é»˜è®¤ä½¿ç”¨ LLM

### è§£å†³æ–¹æ¡ˆ

**ä¿®æ”¹ `ai-say-action.ts`ï¼Œä½¿å…¶é»˜è®¤è°ƒç”¨ LLM**ï¼š

```typescript
// ä¹‹å‰ï¼šéœ€è¦é…ç½® use_llm: true
const useLLM = this.config.use_llm || this.config.useLLM || false;
if (useLLM && this.llmOrchestrator) {
  // è°ƒç”¨ LLM
}

// ç°åœ¨ï¼šé»˜è®¤è°ƒç”¨ LLM
if (this.llmOrchestrator) {
  // è°ƒç”¨ LLM
} else {
  console.warn('âš ï¸ LLMOrchestrator not available, using template content directly');
}
```

### å½±å“

1. **æ‰€æœ‰ ai_say Action ç°åœ¨éƒ½ä¼šè°ƒç”¨ LLM**
2. **ä¸éœ€è¦å†é…ç½® `use_llm: true`**
3. **é¦–æ¡æ¶ˆæ¯å’Œåç»­æ¶ˆæ¯è¡Œä¸ºä¸€è‡´**
4. **LLM è°ƒè¯•ä¿¡æ¯ï¼ˆæç¤ºè¯å’Œå“åº”ï¼‰ä¼šæ­£å¸¸æ˜¾ç¤º**

### è„šæœ¬é…ç½®ç¤ºä¾‹

**ä¹‹å‰ï¼ˆé”™è¯¯ï¼‰**ï¼š
```yaml
- action_id: action_1
  action_type: ai_say
  config:
    content: "æ¬¢è¿æ¥åˆ°æ¸¸å¿ƒè°·å¿ƒç†å’¨è¯¢æœåŠ¡"
    use_llm: true  # âŒ ä¸åº”è¯¥éœ€è¦è¿™ä¸ªé…ç½®
    require_acknowledgment: false
```

**ç°åœ¨ï¼ˆæ­£ç¡®ï¼‰**ï¼š
```yaml
- action_id: action_1
  action_type: ai_say
  config:
    content: "æ¬¢è¿æ¥åˆ°æ¸¸å¿ƒè°·å¿ƒç†å’¨è¯¢æœåŠ¡"
    require_acknowledgment: false
```

### æŠ€æœ¯ç»†èŠ‚

**æ–‡ä»¶**: `packages/core-engine/src/actions/ai-say-action.ts`

**ä¿®æ”¹å†…å®¹**ï¼š
1. ç§»é™¤ `use_llm` é…ç½®æ£€æŸ¥
2. é»˜è®¤è°ƒç”¨ `this.llmOrchestrator.generateText()`
3. ä»…åœ¨ LLMOrchestrator ä¸å¯ç”¨æ—¶ä½¿ç”¨æ¨¡æ¿å†…å®¹ï¼ˆå¹¶è¾“å‡ºè­¦å‘Šæ—¥å¿—ï¼‰

**LLM æç¤ºè¯æ¨¡æ¿**ï¼š
```typescript
const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å’¨è¯¢å¸ˆï¼Œè¯·å°†ä»¥ä¸‹å†…å®¹æ”¹å†™ä¸ºæ›´è‡ªç„¶ã€æ›´æ¸©æš–çš„è¡¨è¾¾æ–¹å¼ï¼Œä¿æŒåŸæ„ä¸å˜ã€‚`;
const userPrompt = `è¯·æ”¹å†™ï¼š${content}`;
```

### éªŒè¯æ–¹æ³•

1. **å¯åŠ¨å¼€å‘æœåŠ¡å™¨**: `pnpm dev`
2. **è§‚å¯Ÿæ—¥å¿—**ï¼Œåº”è¯¥çœ‹åˆ°ï¼š
   ```
   [ScriptExecutor] ğŸ¤– LLM Orchestrator initialized: {
     provider: 'volcano',
     endpointId: 'deepseek-v3-250324',
     hasApiKey: true,
     baseUrl: 'https://ark.cn-beijing.volces.com/api/v3'
   }
   ```
3. **åˆ›å»ºè°ƒè¯•ä¼šè¯**
4. **è§‚å¯Ÿ ai_say æ‰§è¡Œæ—¥å¿—**ï¼š
   ```
   [AiSayAction] ğŸ¤– Using LLM to generate natural expression
   [AiSayAction] âœ… LLM generated: [è‡ªç„¶åŒ–çš„æ–‡æœ¬]
   [ScriptExecutor] ğŸ’¾ Saved LLM debug info: { hasPrompt: true, hasResponse: true, model: 'deepseek-v3-250324' }
   ```
5. **åœ¨è°ƒè¯•é¢æ¿ä¸­çœ‹åˆ°**ï¼š
   - ğŸ”µ è“è‰²çš„ LLM æç¤ºè¯æ°”æ³¡
   - ğŸŸ£ ç´«è‰²çš„ LLM å“åº”æ°”æ³¡
   - âœ… AI æ¶ˆæ¯æ˜¯ç»è¿‡ LLM æ”¹å†™çš„è‡ªç„¶è¡¨è¾¾ï¼ˆä¸å†æ˜¯ç¡¬ç¼–ç çš„æ¨¡æ¿æ–‡æœ¬ï¼‰

### ç›¸å…³æ–‡ä»¶

- `packages/core-engine/src/actions/ai-say-action.ts` - ai_say Action å®ç°
- `packages/core-engine/src/engines/script-execution/script-executor.ts` - ScriptExecutorï¼Œåˆå§‹åŒ– LLMOrchestrator
- `packages/api-server/src/services/session-manager.ts` - SessionManagerï¼Œä½¿ç”¨ ScriptExecutor

### ç¯å¢ƒé…ç½®

ç¡®ä¿ `.env` æ–‡ä»¶ä¸­é…ç½®äº†ç«å±±å¼•æ“ APIï¼š

```env
VOLCANO_API_KEY=your-api-key-here
VOLCANO_ENDPOINT_ID=deepseek-v3-250324
VOLCANO_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
```

---

## æ€»ç»“

âœ… **ai_say ç°åœ¨é»˜è®¤è°ƒç”¨ LLM**  
âœ… **æ— éœ€é¢å¤–é…ç½® `use_llm: true`**  
âœ… **æ‰€æœ‰ ai_say è¾“å‡ºéƒ½ç»è¿‡ LLM ç”Ÿæˆ**  
âœ… **è¡Œä¸ºä¸€è‡´æ€§å¾—åˆ°ä¿è¯**  
âœ… **LLM è°ƒè¯•ä¿¡æ¯æ­£å¸¸æ˜¾ç¤º**
