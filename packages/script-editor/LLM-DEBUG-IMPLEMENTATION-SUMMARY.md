# LLM è°ƒè¯•ä¿¡æ¯åŠŸèƒ½å®ç°æ€»ç»“

## æ¦‚è¿°

æœ¬æ¬¡å®ç°å®Œæˆäº† LLM æç¤ºè¯å’Œå“åº”çš„è°ƒè¯•ä¿¡æ¯æ•è·ä¸å±•ç¤ºåŠŸèƒ½ï¼Œä½¿ç¼–è¾‘å™¨èƒ½å¤Ÿå®æ—¶æ˜¾ç¤ºå‘é€ç»™ AI çš„å®Œæ•´æç¤ºè¯å’Œ AI çš„åŸå§‹å“åº”å†…å®¹ã€‚

## å·²å®Œæˆå·¥ä½œï¼ˆåç«¯ï¼‰

### 1. LLM Orchestrator å¢å¼º âœ…

**æ–‡ä»¶**: `packages/core-engine/src/engines/llm-orchestration/orchestrator.ts`

**æ”¹åŠ¨**:
- æ–°å¢ `LLMDebugInfo` æ¥å£ï¼šæ•è· promptã€responseã€modelã€configã€timestampã€tokensUsed
- æ–°å¢ `LLMGenerateResult` æ¥å£ï¼šåŒ…å« text å’Œ debugInfo
- ä¿®æ”¹ `BaseLLMProvider.generateText()`ï¼šè¿”å›å®Œæ•´çš„è°ƒè¯•ä¿¡æ¯

**å…³é”®ä»£ç **:
```typescript
export interface LLMDebugInfo {
  prompt: string;           // å®Œæ•´çš„æç¤ºè¯
  response: any;            // åŸå§‹å“åº”ï¼ˆJSONæ ¼å¼ï¼‰
  model: string;            // ä½¿ç”¨çš„æ¨¡å‹
  config: Partial<LLMConfig>; // LLMé…ç½®
  timestamp: string;        // è°ƒç”¨æ—¶é—´
  tokensUsed?: number;      // ä½¿ç”¨çš„tokenæ•°
}

export interface LLMGenerateResult {
  text: string;             // ç”Ÿæˆçš„æ–‡æœ¬
  debugInfo: LLMDebugInfo;  // è°ƒè¯•ä¿¡æ¯
}
```

### 2. ActionResult æ¥å£æ‰©å±• âœ…

**æ–‡ä»¶**: `packages/core-engine/src/actions/base-action.ts`

**æ”¹åŠ¨**:
- æ·»åŠ  `debugInfo?: LLMDebugInfo` å­—æ®µ

### 3. ExecutionState æ‰©å±• âœ…

**æ–‡ä»¶**: `packages/core-engine/src/engines/script-execution/script-executor.ts`

**æ”¹åŠ¨**:
- æ·»åŠ  `lastLLMDebugInfo?: LLMDebugInfo` å­—æ®µ
- åœ¨å¤„ç† ActionResult æ—¶ä¿å­˜ debugInfo

### 4. Session Manager API å“åº”å¢å¼º âœ…

**æ–‡ä»¶**: `packages/api-server/src/services/session-manager.ts`

**æ”¹åŠ¨**:
- `initializeSession()` è¿”å›å€¼æ·»åŠ  `debugInfo?: any`
- `processUserInput()` è¿”å›å€¼æ·»åŠ  `debugInfo?: any`
- åœ¨å“åº”ä¸­åŒ…å« `executionState.lastLLMDebugInfo`

### 5. å˜é‡æå–å™¨æ›´æ–° âœ…

**æ–‡ä»¶**: `packages/core-engine/src/engines/variable-extraction/extractor.ts`

**æ”¹åŠ¨**:
- ä¿®æ”¹ä»¥é€‚é…æ–°çš„ `LLMGenerateResult` æ¥å£
- ä½¿ç”¨ `result.text` è€Œéç›´æ¥ä½¿ç”¨ `result`

## å·²å®Œæˆå·¥ä½œï¼ˆå‰ç«¯ï¼‰

### 6. LLMResponseBubble ç»„ä»¶ âœ…

**æ–‡ä»¶**: `packages/script-editor/src/components/DebugBubbles/LLMResponseBubble.tsx`

**ç»„ä»¶è¦æ±‚**:
- æ˜¾ç¤ºæ¨¡å‹åç§°
- æ˜¾ç¤º token ä½¿ç”¨é‡
- JSON æ ¼å¼å±•ç¤ºåŸå§‹å“åº”
- æ”¯æŒæŠ˜å /å±•å¼€
- æ”¯æŒå¤åˆ¶ JSON å†…å®¹
- è“è‰²/ç´«è‰²ä¸»é¢˜ï¼ˆåŒºåˆ†äºæç¤ºè¯çš„è“è‰²ï¼‰

**å‚è€ƒæ¥å£**:
```typescript
interface LLMResponseBubbleProps {
  content: LLMResponseBubbleContent;
  isExpanded: boolean;
  timestamp: string;
  actionId?: string;
  onToggleExpand: () => void;
}

interface LLMResponseBubbleContent {
  type: 'llm_response';
  model: string;
  tokens: number;
  maxTokens: number;
  rawResponse: string;
  processedResponse: string;
  preview: string;
}
```

### 7. DebugChatPanel é›†æˆ âœ…

**æ–‡ä»¶**: `packages/script-editor/src/components/DebugChatPanel/index.tsx`

**éœ€è¦ä¿®æ”¹çš„ä½ç½®**:

#### 7.1 åœ¨ handleSendMessage ä¸­è§£æ debugInfo

```typescript
// åœ¨æ¥æ”¶åˆ°å“åº”å
const response = await debugApi.sendDebugMessage(sessionId, { content: userMessage });

// æ£€æŸ¥æ˜¯å¦åŒ…å« LLM è°ƒè¯•ä¿¡æ¯
if ((response as any).debugInfo) {
  const debugInfo = (response as any).debugInfo;
  
  // åˆ›å»º LLM æç¤ºè¯æ°”æ³¡
  const promptBubble: DebugBubble = {
    id: uuidv4(),
    type: 'llm_prompt',
    timestamp: debugInfo.timestamp,
    isExpanded: false,
    actionId: (response as any).position?.actionId,
    actionType: (response as any).position?.actionType,
    content: {
      type: 'llm_prompt',
      systemPrompt: debugInfo.systemPrompt || '',
      userPrompt: debugInfo.prompt,
      conversationHistory: debugInfo.conversationHistory || [],
      preview: debugInfo.prompt.substring(0, 100) + '...',
    } as LLMPromptBubbleContent,
  };
  addDebugBubble(promptBubble);

  // åˆ›å»º LLM å“åº”æ°”æ³¡
  const responseBubble: DebugBubble = {
    id: uuidv4(),
    type: 'llm_response',
    timestamp: debugInfo.timestamp,
    isExpanded: false,
    actionId: (response as any).position?.actionId,
    actionType: (response as any).position?.actionType,
    content: {
      type: 'llm_response',
      model: debugInfo.model,
      tokens: debugInfo.tokensUsed || 0,
      maxTokens: debugInfo.config?.maxTokens || 0,
      rawResponse: JSON.stringify(debugInfo.response, null, 2),
      processedResponse: debugInfo.response.text || '',
      preview: (debugInfo.response.text || '').substring(0, 100) + '...',
    } as LLMResponseBubbleContent,
  };
  addDebugBubble(responseBubble);
}
```

#### 7.2 åœ¨æ¶ˆæ¯æ¸²æŸ“ä¸­æ·»åŠ  LLM æ°”æ³¡ç±»å‹

```typescript
{bubble.type === 'llm_prompt' && (
  <LLMPromptBubble
    content={bubble.content as LLMPromptBubbleContent}
    isExpanded={bubble.isExpanded}
    timestamp={bubble.timestamp}
    actionId={bubble.actionId}
    onToggleExpand={() => toggleBubbleExpand(bubble.id)}
  />
)}
{bubble.type === 'llm_response' && (
  <LLMResponseBubble
    content={bubble.content as LLMResponseBubbleContent}
    isExpanded={bubble.isExpanded}
    timestamp={bubble.timestamp}
    actionId={bubble.actionId}
    onToggleExpand={() => toggleBubbleExpand(bubble.id)}
  />
)}
```

## API å“åº”ç¤ºä¾‹

æˆåŠŸè°ƒç”¨LLMåï¼ŒAPI å“åº”å°†åŒ…å«ï¼š

```json
{
  "aiMessage": "ä½ å¥½ï¼Œè¯·é—®ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ",
  "sessionStatus": "active",
  "executionStatus": "waiting_input",
  "variables": { ... },
  "position": { ... },
  "debugInfo": {
    "prompt": "System: ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å’¨è¯¢å¸ˆ...\n\nUser: ä½ å¥½\n\nè¯·å‘ç”¨æˆ·è¯¢é—®å§“åã€‚",
    "response": {
      "text": "ä½ å¥½ï¼Œè¯·é—®ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ",
      "finishReason": "stop",
      "usage": {
        "promptTokens": 125,
        "completionTokens": 12,
        "totalTokens": 137
      },
      "raw": { ... }
    },
    "model": "gpt-3.5-turbo",
    "config": {
      "model": "gpt-3.5-turbo",
      "temperature": 0.7,
      "maxTokens": 2000,
      ...
    },
    "timestamp": "2026-01-18T17:30:45.123Z",
    "tokensUsed": 137
  }
}
```

## æ•°æ®æµ

```
1. ç”¨æˆ·å‘é€æ¶ˆæ¯
   â†“
2. SessionManager.processUserInput()
   â†“
3. ScriptExecutor.executeSession()
   â†“
4. Action.execute() (å¦‚ AiAskAction)
   â†“
5. LLMOrchestrator.generateText()
   â†“
6. BaseLLMProvider.generateText()
   - è°ƒç”¨ LLM API
   - æ•è· prompt å’Œ response
   - è¿”å› LLMGenerateResult { text, debugInfo }
   â†“
7. Action è¿”å› ActionResult { ..., debugInfo }
   â†“
8. ScriptExecutor ä¿å­˜åˆ° ExecutionState.lastLLMDebugInfo
   â†“
9. SessionManager åœ¨å“åº”ä¸­åŒ…å« debugInfo
   â†“
10. å‰ç«¯æ¥æ”¶å“åº”ï¼Œè§£æ debugInfo
    â†“
11. åˆ›å»º LLM æç¤ºè¯å’Œå“åº”æ°”æ³¡
    â†“
12. åœ¨è°ƒè¯•é¢æ¿ä¸­å±•ç¤º
```

## ç¼–è¯‘çŠ¶æ€

- âœ… core-engine: ç¼–è¯‘æˆåŠŸ
- âœ… api-server: ç¼–è¯‘æˆåŠŸ
- â³ script-editor: å¾…å®Œæˆå‰ç«¯ç»„ä»¶åç¼–è¯‘

## ä½¿ç”¨è¯´æ˜ï¼ˆå®Œæˆåï¼‰

### å¼€å¯ LLM è°ƒè¯•ä¿¡æ¯

åœ¨è°ƒè¯•é¢æ¿ä¸­ï¼š
1. ç‚¹å‡»æ ‡é¢˜æ çš„è®¾ç½®å›¾æ ‡ï¼ˆâš™ï¸ï¼‰
2. å‹¾é€‰"ğŸ’¡ LLM æç¤ºè¯"
3. å‹¾é€‰"ğŸ¤– LLM å“åº”"
4. ç‚¹å‡»"ç¡®å®š"

### æŸ¥çœ‹æç¤ºè¯

- è“è‰²æ°”æ³¡æ˜¾ç¤ºå‘é€ç»™ LLM çš„å®Œæ•´æç¤ºè¯
- åŒ…å«ç³»ç»Ÿæç¤ºè¯ã€ç”¨æˆ·æç¤ºè¯ã€å¯¹è¯å†å²
- ç‚¹å‡»"å±•å¼€è¯¦æƒ…"æŸ¥çœ‹å®Œæ•´å†…å®¹

### æŸ¥çœ‹å“åº”

- ç´«è‰²/æ·±è“è‰²æ°”æ³¡æ˜¾ç¤º LLM çš„åŸå§‹å“åº”
- JSON æ ¼å¼å±•ç¤ºå“åº”å¯¹è±¡
- æ˜¾ç¤º token ä½¿ç”¨é‡
- å¯å¤åˆ¶ JSON å†…å®¹ç”¨äºåˆ†æ

## æ€§èƒ½è€ƒè™‘

- LLM è°ƒè¯•ä¿¡æ¯å¯èƒ½è¾ƒå¤§ï¼ˆç‰¹åˆ«æ˜¯é•¿å¯¹è¯å†å²ï¼‰
- é»˜è®¤å…³é—­ LLM æç¤ºè¯å’Œå“åº”å±•ç¤º
- ä»…åœ¨éœ€è¦è°ƒè¯•æ—¶å¼€å¯
- è€ƒè™‘é™åˆ¶æ˜¾ç¤ºçš„å¯¹è¯å†å²æ¡æ•°ï¼ˆå·²åœ¨ä»£ç ä¸­å®ç°æ»‘åŠ¨çª—å£ï¼‰

## ä¸‹ä¸€æ­¥å·¥ä½œ

### ç«¯åˆ°ç«¯æµ‹è¯•

1. **å¯åŠ¨å¼€å‘ç¯å¢ƒ**
   ```bash
   # åœ¨é¡¹ç›®æ ¹ç›®å½•
   pnpm dev
   ```

2. **æ‰“å¼€è°ƒè¯•é¢æ¿**
   - è®¿é—® script-editor
   - åˆ›å»ºæˆ–æ‰“å¼€ä¸€ä¸ªè°ƒè¯•ä¼šè¯
   - åœ¨å³ä¾§æ‰“å¼€è°ƒè¯•èŠå¤©é¢æ¿

3. **å¯ç”¨ LLM è°ƒè¯•ä¿¡æ¯æ˜¾ç¤º**
   - ç‚¹å‡»è¿‡æ»¤å™¨æŒ‰é’®ï¼ˆæ¼æ–—å›¾æ ‡ï¼‰
   - å‹¾é€‰ "LLM æç¤ºè¯" å’Œ "LLM å“åº”"
   - ä¿å­˜è®¾ç½®

4. **å‘é€æ¶ˆæ¯è§¦å‘ LLM è°ƒç”¨**
   - åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥æ¶ˆæ¯
   - å‘é€åè§‚å¯Ÿæ˜¯å¦æ˜¾ç¤º LLM è°ƒè¯•ä¿¡æ¯æ°”æ³¡

5. **éªŒè¯åŠŸèƒ½**
   - æ£€æŸ¥æ˜¯å¦æ˜¾ç¤º LLM æç¤ºè¯æ°”æ³¡ï¼ˆè“è‰²ï¼‰
   - æ£€æŸ¥æ˜¯å¦æ˜¾ç¤º LLM å“åº”æ°”æ³¡ï¼ˆç´«è‰²ï¼‰
   - ç‚¹å‡»å±•å¼€ï¼ŒéªŒè¯å®Œæ•´æç¤ºè¯å’Œ JSON å“åº”
   - æµ‹è¯•å¤åˆ¶ JSON åŠŸèƒ½
   - æµ‹è¯•æŠ˜å /å±•å¼€åŠŸèƒ½

6. **æŸ¥çœ‹æ§åˆ¶å°æ—¥å¿—**
   ```javascript
   // åº”è¯¥çœ‹åˆ°ç±»ä¼ºçš„æ—¥å¿—
   [DebugChat] ğŸ“ Received LLM debugInfo: {...}
   [DebugChat] âœ… Created LLM prompt and response bubbles
   ```

### è°ƒè¯•æŠ€å·§

å¦‚æœ LLM è°ƒè¯•ä¿¡æ¯æœªæ˜¾ç¤ºï¼š

1. **æ£€æŸ¥åç«¯æ˜¯å¦è¿”å› debugInfo**
   - æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·
   - æŸ¥çœ‹ Network é€‰é¡¹å¡
   - æ‰¾åˆ° `/api/debug/sessions/{sessionId}/messages` çš„å“åº”
   - æ£€æŸ¥å“åº”ä½“ä¸­æ˜¯å¦åŒ…å« `debugInfo` å­—æ®µ

2. **æ£€æŸ¥å‰ç«¯è§£æé€»è¾‘**
   - æ‰“å¼€æµè§ˆå™¨æ§åˆ¶å°
   - æŸ¥çœ‹æ˜¯å¦æœ‰ `[DebugChat]` ç›¸å…³çš„æ—¥å¿—
   - æ£€æŸ¥ debugInfo çš„ç»“æ„æ˜¯å¦æ­£ç¡®

3. **æ£€æŸ¥è¿‡æ»¤å™¨è®¾ç½®**
   - ç¡®è®¤ LLM æç¤ºè¯å’Œ LLM å“åº”çš„è¿‡æ»¤å™¨å·²å¯ç”¨
   - æ£€æŸ¥ localStorage ä¸­çš„ `debugOutputFilter` é”®

4. **é‡æ–°ç¼–è¯‘**
   ```bash
   pnpm run build
   pnpm dev
   ```

### æ–‡æ¡£æ›´æ–°

å»ºè®®æ›´æ–°ä»¥ä¸‹æ–‡æ¡£ï¼š
- ç”¨æˆ·æ‰‹å†Œï¼šå¦‚ä½•ä½¿ç”¨ LLM è°ƒè¯•ä¿¡æ¯
- å¼€å‘è€…æ–‡æ¡£ï¼šå¦‚ä½•æ‰©å±•è°ƒè¯•ä¿¡æ¯ç³»ç»Ÿ
- æˆªå›¾ç¤ºä¾‹ï¼šå±•ç¤º LLM è°ƒè¯•ä¿¡æ¯çš„å¤–è§‚

---

*å®ç°æ—¶é—´*ï¼š2026-01-18  
*æ–‡æ¡£ç‰ˆæœ¬*ï¼šv2.0  
*çŠ¶æ€*ï¼šâœ… **å…¨éƒ¨å®Œæˆ**ï¼ˆåç«¯ + å‰ç«¯ï¼‰

## å®ç°æ€»ç»“

### å·²å®Œæˆçš„åŠŸèƒ½

1. **åç«¯å®Œæ•´å®ç°** âœ…
   - LLM Orchestrator æ•è·è°ƒè¯•ä¿¡æ¯
   - ActionResult ä¼ é€’ debugInfo
   - ExecutionState ä¿å­˜ lastLLMDebugInfo
   - Session Manager API å“åº”åŒ…å« debugInfo
   - ç¼–è¯‘æˆåŠŸï¼Œæ— é”™è¯¯

2. **å‰ç«¯å®Œæ•´å®ç°** âœ…
   - LLMPromptBubble ç»„ä»¶ï¼ˆå·²å­˜åœ¨ï¼‰
   - LLMResponseBubble ç»„ä»¶ï¼ˆæ–°åˆ›å»ºï¼‰
   - DebugChatPanel é›†æˆï¼ˆå·²å®Œæˆï¼‰
   - debugInfo è§£æé€»è¾‘ï¼ˆå·²å®Œæˆï¼‰
   - æ°”æ³¡æ¸²æŸ“é€»è¾‘ï¼ˆå·²å®Œæˆï¼‰
   - ç¼–è¯‘æˆåŠŸï¼Œæ— é”™è¯¯

3. **æ•°æ®æµå®Œæ•´** âœ…
   - LLM å±‚ â†’ Action å±‚ â†’ ExecutionState â†’ Session Manager â†’ API â†’ å‰ç«¯
   - ç±»å‹å®‰å…¨ï¼Œå…¨é“¾è·¯ TypeScript ç±»å‹å®šä¹‰

### æ ¸å¿ƒç‰¹æ€§

- ğŸ“ **å®Œæ•´æç¤ºè¯å±•ç¤º**ï¼šæ˜¾ç¤ºå‘é€ç»™ LLM çš„å®Œæ•´æç¤ºè¯ï¼ˆåŒ…æ‹¬ç³»ç»Ÿæç¤ºã€ç”¨æˆ·æç¤ºã€å†å²å¯¹è¯ï¼‰
- ğŸ“Š **JSON å“åº”å±•ç¤º**ï¼šä»¥ JSON æ ¼å¼æ˜¾ç¤º LLM çš„åŸå§‹å“åº”
- ğŸ¨ **å‹å¥½çš„ UI**ï¼šè“è‰²æç¤ºè¯æ°”æ³¡ + ç´«è‰²å“åº”æ°”æ³¡
- ğŸ”„ **æŠ˜å /å±•å¼€**ï¼šæ”¯æŒæŠ˜å å’Œå±•å¼€è¯¦ç»†ä¿¡æ¯
- ğŸ“‹ **å¤åˆ¶åŠŸèƒ½**ï¼šä¸€é”®å¤åˆ¶æç¤ºè¯å’Œ JSON å“åº”
- ğŸ¯ **è¿‡æ»¤å™¨æ”¯æŒ**ï¼šå¯ä»¥é€šè¿‡è¿‡æ»¤å™¨å¼€å…³ LLM è°ƒè¯•ä¿¡æ¯æ˜¾ç¤º
- ğŸ’¾ **æŒä¹…åŒ–**ï¼šè¿‡æ»¤å™¨è®¾ç½®ä¿å­˜åœ¨ localStorage

### ä¿®æ”¹çš„æ–‡ä»¶æ¸…å•

**åç«¯** (5 ä¸ªæ–‡ä»¶):
1. `packages/core-engine/src/engines/llm-orchestration/orchestrator.ts`
2. `packages/core-engine/src/actions/base-action.ts`
3. `packages/core-engine/src/engines/script-execution/script-executor.ts`
4. `packages/core-engine/src/engines/variable-extraction/extractor.ts`
5. `packages/api-server/src/services/session-manager.ts`

**å‰ç«¯** (2 ä¸ªæ–‡ä»¶):
1. `packages/script-editor/src/components/DebugBubbles/LLMResponseBubble.tsx` (æ–°å»º)
2. `packages/script-editor/src/components/DebugChatPanel/index.tsx` (ä¿®æ”¹)

### æ€§èƒ½ä¼˜åŒ–

- é»˜è®¤å…³é—­ LLM è°ƒè¯•ä¿¡æ¯æ˜¾ç¤ºï¼Œå‡å°‘æ€§èƒ½å¼€é”€
- ä»…åœ¨éœ€è¦è°ƒè¯•æ—¶æ‰å¼€å¯
- å¯¹è¯å†å²ä½¿ç”¨æ»‘åŠ¨çª—å£ï¼Œé¿å…æ•°æ®è¿‡å¤§

### ä¸‹ä¸€æ­¥å»ºè®®

1. è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•
2. æ·»åŠ è¯­æ³•é«˜äº®ï¼ˆå¯é€‰ï¼‰
3. æ”¯æŒæœç´¢å’Œè¿‡æ»¤æç¤ºè¯å†…å®¹ï¼ˆå¯é€‰ï¼‰
4. æ›´æ–°ç”¨æˆ·æ–‡æ¡£å’Œæˆªå›¾
