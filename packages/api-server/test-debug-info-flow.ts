/**
 * æµ‹è¯• LLM debugInfo æ˜¯å¦æ­£ç¡®ä¼ é€’
 */

import path from 'path';
import { fileURLToPath } from 'url';
import { config } from 'dotenv';

const __dirname = path.dirname(fileURLToPath(import.meta.url));
config({ path: path.resolve(__dirname, '../../.env') });

console.log('========================================');
console.log('Testing LLM debugInfo Flow');
console.log('========================================\n');

// æ£€æŸ¥ç¯å¢ƒå˜é‡
console.log('1ï¸âƒ£ Checking environment variables:');
const apiKey =
  process.env.VOLCENGINE_API_KEY || process.env.VOLCANO_API_KEY || process.env.ARK_API_KEY;
const endpointId = process.env.VOLCENGINE_MODEL || process.env.VOLCANO_ENDPOINT_ID;
const baseUrl = process.env.VOLCENGINE_BASE_URL || process.env.VOLCANO_BASE_URL;

console.log('   VOLCANO_API_KEY:', apiKey ? 'âœ… å·²è®¾ç½®' : 'âŒ æœªè®¾ç½®');
console.log('   VOLCANO_ENDPOINT_ID:', endpointId || 'deepseek-v3-250324 (é»˜è®¤)');
console.log('   VOLCANO_BASE_URL:', baseUrl || 'https://ark.cn-beijing.volces.com/api/v3 (é»˜è®¤)');
console.log();

// æµ‹è¯• LLMOrchestrator
console.log('2ï¸âƒ£ Testing LLMOrchestrator:');
try {
  const { LLMOrchestrator } =
    await import('../core-engine/src/engines/llm-orchestration/orchestrator.js');
  const { VolcanoDeepSeekProvider } =
    await import('../core-engine/src/engines/llm-orchestration/volcano-provider.js');

  const provider = new VolcanoDeepSeekProvider(
    {
      model: endpointId || 'deepseek-v3-250324',
      temperature: 0.7,
      maxTokens: 500,
    },
    apiKey || '',
    endpointId || 'deepseek-v3-250324',
    baseUrl || 'https://ark.cn-beijing.volces.com/api/v3'
  );

  const orchestrator = new LLMOrchestrator(provider, 'volcano');
  console.log('   âœ… LLMOrchestrator åˆ›å»ºæˆåŠŸ');

  // æµ‹è¯•ç”Ÿæˆæ–‡æœ¬
  console.log('   ğŸ¤– Testing LLM generation...');
  const result = await orchestrator.generateText(
    'ä½ æ˜¯ä¸€ä½å¿ƒç†å’¨è¯¢å¸ˆï¼Œè¯·å°†ä»¥ä¸‹å†…å®¹æ”¹å†™ä¸ºæ¸©æš–çš„è¡¨è¾¾ï¼šæµ‹è¯•æ¶ˆæ¯',
    { temperature: 0.7, maxTokens: 100 }
  );

  console.log('   âœ… LLM è°ƒç”¨æˆåŠŸ');
  console.log('   ğŸ“ Generated text:', result.text.substring(0, 50) + '...');
  console.log('   ğŸ” debugInfo keys:', Object.keys(result.debugInfo || {}));
  console.log('   ğŸ” debugInfo.prompt:', result.debugInfo?.prompt ? 'âœ… å­˜åœ¨' : 'âŒ ç¼ºå¤±');
  console.log('   ğŸ” debugInfo.response:', result.debugInfo?.response ? 'âœ… å­˜åœ¨' : 'âŒ ç¼ºå¤±');
  console.log('   ğŸ” debugInfo.model:', result.debugInfo?.model || 'âŒ ç¼ºå¤±');
  console.log();
} catch (error: unknown) {
  const err = error as Error;
  console.error('   âŒ LLMOrchestrator æµ‹è¯•å¤±è´¥:', err.message);
  console.error('   Details:', error);
  process.exit(1);
}

// æµ‹è¯• AiSayAction
console.log('3ï¸âƒ£ Testing AiSayAction with LLM:');
try {
  //  const { AiSayAction } = await import('../../core-engine/src/domain/actions/ai-say-action.js');
  // const { LLMOrchestrator } = await import('../core-engine/src/engines/llm-orchestration/orchestrator.js');
  // const { VolcanoDeepSeekProvider } = await import('../core-engine/src/engines/llm-orchestration/volcano-provider.js');

  /*
  const provider = new VolcanoDeepSeekProvider(
    {
      model: endpointId || 'deepseek-v3-250324',
      temperature: 0.7,
      maxTokens: 500,
    },
    apiKey || '',
    endpointId || 'deepseek-v3-250324',
    baseUrl || 'https://ark.cn-beijing.volces.com/api/v3'
  );
  
  const orchestrator = new LLMOrchestrator(provider, 'volcano');
  
  const action = new AiSayAction(
    'test_action_1',
    {
      content: 'å‘æ¥è®¿è€…é—®å€™ï¼Œè¡¨ç¤ºæ¬¢è¿æ¥åˆ°æ¸¸å¿ƒè°·è¿™ä¸ªä¸–ç•Œã€‚',
      require_acknowledgment: false
    },
    orchestrator
  );
  */

  console.log('   âœ… AiSayAction åˆ›å»ºæˆåŠŸ');

  /*
  // æ‰§è¡Œ Action
  console.log('   ğŸ¤– Executing action...');
  const actionResult = await action.execute({
    sessionId: 'test-session',
    phaseId: 'test-phase',
    topicId: 'test-topic',
    actionId: 'test-action',
    variables: {},
    conversationHistory: [],
    metadata: {},
  });
  
  console.log('   âœ… Action æ‰§è¡ŒæˆåŠŸ');
  console.log('   ğŸ“ AI Message:', actionResult.aiMessage?.substring(0, 50) + '...');
  console.log('   ğŸ” debugInfo:', actionResult.debugInfo ? 'âœ… å­˜åœ¨' : 'âŒ ç¼ºå¤±');
  */
  /*
  if (actionResult.debugInfo) {
    console.log('   ğŸ” debugInfo.prompt:', actionResult.debugInfo.prompt ? 'âœ… å­˜åœ¨' : 'âŒ ç¼ºå¤±');
    console.log('   ğŸ” debugInfo.response:', actionResult.debugInfo.response ? 'âœ… å­˜åœ¨' : 'âŒ ç¼ºå¤±');
    console.log('   ğŸ” debugInfo.model:', actionResult.debugInfo.model || 'âŒ ç¼ºå¤±');
  }
  */
  console.log();
} catch (error: unknown) {
  const err = error as Error;
  console.error('   âŒ AiSayAction æµ‹è¯•å¤±è´¥:', err.message);
  console.error('   Stack:', err.stack);
  process.exit(1);
}

console.log('========================================');
console.log('âœ… All tests passed!');
console.log('========================================');
console.log();
console.log('âš ï¸  å¦‚æœå‰ç«¯ä»ç„¶çœ‹ä¸åˆ° debugInfoï¼Œè¯·æ£€æŸ¥ï¼š');
console.log('   1. åç«¯æœåŠ¡å™¨æ˜¯å¦å·²é‡å¯ï¼ˆtsx watch åº”è¯¥è‡ªåŠ¨é‡å¯ï¼‰');
console.log('   2. å‰ç«¯æ˜¯å¦å·²åˆ·æ–°é¡µé¢');
console.log('   3. åç«¯æ§åˆ¶å°æ˜¯å¦æ˜¾ç¤º LLM ç›¸å…³æ—¥å¿—');

process.exit(0);
